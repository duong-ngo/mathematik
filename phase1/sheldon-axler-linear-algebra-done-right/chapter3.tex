\chapter{Linear Maps}

\section{Vector Space of Linear Maps}

% chapter3:sectionA:exercise1
\begin{exercise}
    Suppose $b, c\in\mathbb{R}$. Define $T: \mathbb{R}^{3}\to \mathbb{R}^{2}$ by
    \[
        T(x, y, z) = (2x - 4y + 3z + b, 6x + cxyz).
    \]

    Show that $T$ is linear if and only if $b = c = 0$.
\end{exercise}

\begin{proof}
    I skip this exercise.
\end{proof}
\newpage

% chapter3:sectionA:exercise2
\begin{exercise}
    Suppose $b, c \in \mathbb{R}$ . Define $T: \mathcal{P}(\mathbb{R})\to \mathbb{R}^{2}$ by
    \[
        Tp = \left( 3p(4) + 5p'(6) + bp(1)p(2), \int^{2}_{-1}x^{3}p(x)dx + c \sin p(0) \right)
    \]

    Show that $T$ is linear if and only if $b = c = 0$.
\end{exercise}

\begin{proof}
    I skip this exercise.
\end{proof}
\newpage

% chapter3:sectionA:exercise3
\begin{exercise}
    Suppose that $T\in \mathcal{L}(\mathbb{F}^{n}, \mathbb{F}^{m})$. Show that there exist scalars $A_{j,k}\in\mathbb{F}$ for $j = 1, \ldots, m$ and $k = 1, \ldots, n$ such that
    \[
        T(x_{1}, \ldots, x_{n}) = (A_{1,1}x_{1} + \cdots + A_{1,n}x_{n}, \ldots, A_{m,1}x_{1} + \cdots + A_{m,n}x_{n})
    \]

    for every $(x_{1}, \ldots, x_{n})\in\mathbb{F}^{n}$.
\end{exercise}

\begin{proof}
    Let $e_{1}, \ldots, e_{n}$ be the standard basis of $\mathbb{F}^{n}$ and let $T(e_{i}) = (A_{1,i}, \ldots, A_{m, i})$ for all $i\in\{ 1, 2, \ldots, n \}$. Hence
    \[
        T(x_{1}, \ldots, x_{n}) = (A_{1,1}x_{1} + \cdots + A_{1,n}x_{n}, \ldots, A_{m,1}x_{1} + \cdots + A_{m,n}x_{n})
    \]

    for every $(x_{1}, \ldots, x_{n})\in\mathbb{F}^{n}$.
\end{proof}
\newpage

% chapter3:sectionA:exercise4
\begin{exercise}
    Suppose $T\in \mathcal{L}(V, W)$ and $v_{1}, \ldots, v_{m}$ is a list of vectors in $V$ such that $Tv_{1}, \ldots, Tv_{m}$ is a linearly independent list in $W$. Prove that $v_{1}, \ldots, v_{m}$ is linearly independent.
\end{exercise}

\begin{proof}
    Let $x_{1}v_{1} + \cdots + x_{n}v_{n} = 0$ be a linear combination of $0$ in $V$.
    \[
        0 = T(0) = T(x_{1}v_{1} + \cdots + x_{n}v_{n}) = x_{1}Tv_{1} + \cdots + x_{n}Tv_{n}.
    \]

    Since $Tv_{1}, \ldots, Tv_{n}$ is linearly independent, then $x_{1}, \ldots, x_{n}$ are all zero. Hence $v_{1}, \ldots, v_{n}$ is linearly independent.
\end{proof}
\newpage

% chapter3:sectionA:exercise5
\begin{exercise}
    Prove that $\mathcal{L}(V, W)$ is a vector space, as was asserted in 3.6.
\end{exercise}

\begin{proof}
    I skip this exercise.
\end{proof}
\newpage

% chapter3:sectionA:exercise6
\begin{exercise}
    Prove that multiplication of linear maps has the associative, identity, and distributive properties asserted in 3.8.
\end{exercise}

\begin{proof}
    I skip this exercise.
\end{proof}
\newpage

% chapter3:sectionA:exercise7
\begin{exercise}
    Show that every linear map from a one-dimensional vector space to itself is
    multiplication by some scalar. More precisely, prove that if $\dim V = 1$ and $T\in \mathcal{L}(V)$, then there exists $\lambda\in\mathbb{F}$ such that $Tv = \lambda v$ for all $v\in V$.
\end{exercise}

\begin{proof}
    Let $e$ be a basis of $V$. Then for every $v\in V$, there exists uniquely $x\in\mathbb{F}$ such that $v = xe$, and there exists uniquely $\lambda\in\mathbb{F}$ such that $Te = \lambda e$.
    \[
        Tv = T(xe) = xTe = x(\lambda e) = (x\lambda)e = (\lambda x)e = \lambda(xe) = \lambda v.
    \]

    Hence the result follows.
\end{proof}
\newpage

% chapter3:sectionA:exercise8
\begin{exercise}
    Give an example of a function $\varphi: \mathbb{R}^{2}\to \mathbb{R}$ such that
    \[
        \varphi(av) = a\varphi(v)
    \]

    for all $a\in\mathbb{R}$ and all $v\in\mathbb{R}^{2}$ but $\varphi$ is not linear.
\end{exercise}

\begin{proof}
    $\varphi: (x, y) \mapsto \sqrt[3]{x^{3} + y^{3}}$ satisfies
    \[
        \varphi(ax, ay) = a\varphi(x, y)
    \]

    but $\varphi$ is not linear.
\end{proof}
\newpage

% chapter3:sectionA:exercise9
\begin{exercise}
    Give an example of a function $\varphi: \mathbb{C}\to \mathbb{C}$ such that
    \[
        \varphi(w + z) = \varphi(w) + \varphi(z)
    \]

    for all $w, z\in\mathbb{C}$ but $\varphi$ is not linear. (Here $\mathbb{C}$ is thought of as a complex vector space.)
\end{exercise}

\begin{proof}
    $\varphi: \mathbb{C}\to \mathbb{C}$ defined by
    \[
        \varphi(z) = \bar{z}
    \]

    satisfies $\varphi(z + w) = \varphi(z) + \varphi(w)$ but is not linear.
\end{proof}
\newpage

% chapter3:sectionA:exercise10
\begin{exercise}
    Prove or give a counterexample: If $q\in \mathcal{P}(\mathbb{R})$ and $T: \mathcal{P}(\mathbb{R})\to \mathcal{P}(\mathbb{R})$ is defined by $Tp = q\circ p$, then $T$ is a linear map.
\end{exercise}

\begin{proof}
    Here is a counterexample.

    $q(x) = 1$. $Tp = q\circ p$ then $(Tp)(x) = q(p(x)) = 1$ for all $x\in\mathbb{R}$. $T$ is not a linear map because
    \[
        (T(p_{1} + p_{2}))(x) = 1\ne 1 + 1 = (Tp_{1})(x) + (Tp_{2})(x)
    \]

    for all $x\in\mathbb{R}$.
\end{proof}
\newpage

% chapter3:sectionA:exercise11
\begin{exercise}\label{chapter3:sectionA:exercise11}
    Suppose $V$ is finite-dimensional and $T\in\mathcal{L}(V)$. Prove that $T$ is a scalar multiple of the identity if and only if $ST = TS$ for every $S\in \mathcal{L}(V)$.
\end{exercise}

\begin{proof}
    Let $v_{1}, \ldots, v_{n}$ be a basis of $V$ and $Tv_{i}$ be $x_{i,1}v_{1} + \cdots + x_{i,n}v_{n}$ for each $i\in\{ 1, \ldots, n \}$.

    Due to the linear map lemma, for each $i\in \{ 1, \ldots, n \}$, there exists $S_{i}$ from $V$ to $V$ such that $S_{i}v_{i} = v_{i}$ and $S_{i}v_{j} = 0$ for every $j\ne i$.
    \begin{align*}
        (S_{i}T)(v_{i}) & = S_{i}(x_{i,1}v_{1} + \cdots + x_{i,n}v_{n}) = x_{i,i}v_{i}     \\
        (TS_{i})(v_{i}) & = T(S_{i}v_{i}) = Tv_{i} = x_{i,1}v_{1} + \cdots + x_{i,n}v_{n}.
    \end{align*}

    Because $S_{i}T = TS_{i}$, and $v_{1}, \ldots, v_{n}$ is linearly independent, from the two formulas above, we deduce that $x_{i,j} = 0$ for every $j\ne i$.

    Due to the linear map lemma, for every pair $i\ne j$ and $i, j\in \{ 1, \ldots, n \}$, there exists a linear map $S_{i,j} = S_{j,i}$ from $V$ to $V$ such that $S_{i,j}v_{i} = v_{j}$, $S_{i,j}v_{j} = v_{i}$ and $S_{i,j}v_{k} = 0$ where $k\ne i, j$.
    \begin{align*}
        (S_{i,j}T)(v_{i}) & = S_{i,j}(x_{i,i}v_{i}) = x_{i,i}v_{j} \\
        (TS_{i,j})(v_{i}) & = Tv_{j} = x_{j,j}v_{j}
    \end{align*}

    Because $S_{i,j}T = TS_{i,j}$, and $v_{1}, \ldots, v_{n}$ is linearly independent, from the two formulas above, we deduce that $x_{i,i} = x_{j,j}$.

    So for every $i\ne j$ in $\{1, \ldots, n\}$, $x_{i,j} = 0$ and $x_{i,i} = x_{j,j}$. Let $x_{1,1} = \lambda$, then $Tv_{i} = \lambda v_{i}$ for every $i\in\{1, \ldots, n\}$. Let $v = x_{1}v_{1} + \cdots + x_{n}v_{n}$ be an arbitrary vector in $V$, then
    \[
        Tv = x_{1}Tv_{1} + \cdots + x_{n}Tv_{n} = \lambda (x_{1}v_{1} + \cdots + x_{n}v_{n}) = \lambda v.
    \]

    Thus $T$ is a scalar multiple of the identity map.
\end{proof}
\newpage

% chapter3:sectionA:exercise12
\begin{exercise}
    Suppose $U$ is a subspace of $V$ with $U\ne V$. Suppose $S\in \mathcal{L}(V, W)$ and $S \ne 0$ (which means that $Su \ne 0$ for some $u \in U$). Define $T : V \to W$ by
    \[
        Tv = \begin{cases}
            Sv & \text{if $v\in U$},                 \\
            0  & \text{if $v\in V$ and $v\notin U$.}
        \end{cases}
    \]

    Prove that $T$ is not a linear map on $V$.
\end{exercise}

\begin{proof}
    Let $u$ be a vector in $U$ such that $Su\ne 0$, $w$ be a vector in $V$ such that $w\notin U$. Then $u + w\notin U$. Due to the definition of $T$, $T(u + w) = 0$. On the other hand, $Tu + Tw = Su + 0 = Su\ne 0$. Therefore $T(u + w)\ne Tu + Tw$, so $T$ is not a linear map on $V$.
\end{proof}
\newpage


% chapter3:sectionA:exercise13
\begin{exercise}\label{chapter3:sectionA:exercise13}
    Suppose $V$ is finite-dimensional. Prove that every linear map on a subspace of $V$ can be extended to a linear map on $V$. In other words, show that if $U$ is a subspace of $V$ and $S \in \mathcal{L}(U, W)$, then there exists $T\in \mathcal{L}(V, W)$ such that $Tu = Su$ for all $u\in U$.
\end{exercise}

\begin{proof}
    Let $u_{1}, \ldots, u_{m}$ be a basis of $U$.

    Since $V$ is finite-dimensional, we can extend the list $u_{1}, \ldots, u_{m}$ to $u_{1}, \ldots, u_{m}, v_{1}, \ldots, v_{n}$ such that the new list is a basis of $V$.

    We define a linear map $T$ from $V$ to $W$ by the images of every vector within $u_{1}, \ldots, u_{m}, v_{1}, \ldots, v_{n}$: $Tu_{1} = Su_{1}$, \ldots, $Tu_{m} = Su_{m}$, $Tv_{1}$ is some vector in $W$, \ldots, $Tv_{n}$ is some vector in $W$. According to this construction, the linear map $T$ is indeed an extension of the linear map $S$.
\end{proof}
\newpage

% chapter3:sectionA:exercise14
\begin{exercise}
    Suppose $V$ is finite-dimensional with $\dim V > 0$, and suppose $W$ is infinite-dimensional. Prove that $\mathcal{L}(V, W)$ is infinite-dimensional.
\end{exercise}

\begin{proof}
    According to Exercise~\ref{chapter2:sectionA:exercise17}, there exists a sequence of vectors $w_{1}, w_{2}, \ldots$ in $W$ such that for every positive integer $n$, the list $w_{1}, w_{2}, \ldots, w_{n}$ is linearly independent.

    Let $m = \dim V$ and $v_{1}, \ldots, v_{m}$ a basis of $V$.

    For each positive integer $n$, let $T_{n}$ be a linear map from $V$ to $W$ such that $T_{n}v_{i} = 0$ for every $i\ne 1$ and $T_{n}v_{1} = w_{n}$. Let $\lambda_{1}T_{1} + \lambda_{2}T_{2} + \cdots + \lambda_{n}T_{n} = 0$ be a linear combination of $0$, from this we deduce that
    \[ \lambda_{1}T_{1}v_{1} + \lambda_{2}T_{2}v_{1} + \cdots + \lambda_{n}T_{n}v_{1} = 0v_{1} = 0 \]

    and the left-hand side is reduced to $\lambda_{1}w_{1} + \lambda_{2}w_{2} + \cdots + \lambda_{n}w_{n} = 0$. Because $w_{1}, \ldots, w_{n}$ is linearly independent, so $\lambda_{1} = \lambda_{2} = \cdots = \lambda_{n} = 0$. Therefore $T_{1}, \ldots, T_{n}$ is linearly independent. Once again, according to Exercise~\ref{chapter2:sectionA:exercise17}, $\mathcal{L}(V, W)$ is infinite-dimensional.
\end{proof}
\newpage

% chapter3:sectionA:exercise15
\begin{exercise}
    Suppose $v_{1} , \ldots, v_{m}$ is a linearly dependent list of vectors in $V$. Suppose also that $W \ne \{0\}$. Prove that there exist $w_{1} , \ldots, w_{m} \in W$ such that no $T \in \mathcal{L}(V, W)$ satisfies $Tv_{k} = w_{k}$ for each $k = 1, \ldots, m$.
\end{exercise}

\begin{proof}
    Because $v_{1} , \ldots, v_{m}$ is a linearly dependent list, there exist scalars $\lambda_{1}, \ldots, \lambda_{m}$ which are not all zero such that $\lambda_{1}v_{1} + \cdots + \lambda_{m}v_{m} = 0$. Without loss of generality, assume that $\lambda_{1}\ne 0$.

    Since $W\ne \{0\}$, there exists a non-zero vector $w_{1}$ in $W$. Let $w_{2} = \cdots = w_{m} = 0$ (they are all zero vector), then $\lambda_{1}w_{1} + \lambda_{2}w_{2} + \cdots + \lambda_{m}w_{k} = \lambda_{1}w_{1}\ne 0$. There does not exist a linear map $T$ from $V$ to $W$ such that $Tv_{k} = w_{k}$ for each $k = 1,\ldots, m$, because $0 = T(\lambda_{1}v_{1} + \lambda_{2}v_{2} + \cdots + \lambda_{m}v_{k}) = \lambda_{1}w_{1} + \lambda_{2}w_{2} + \cdots + \lambda_{m}w_{k} \ne 0$.

    Hence there exist $w_{1}, \ldots, w_{m}\in W$ such that no $T\in\mathcal{L}(V, W)$ satisfies $Tv_{k} = w_{k}$ for each $k = 1, \ldots, m$.
\end{proof}
\newpage

% chapter3:sectionA:exercise16
\begin{exercise}
    Suppose $V$ is finite-dimensional with $\dim V > 1$. Prove that there exist $S, T \in \mathcal{L}(V)$ such that $ST \ne TS$.
\end{exercise}

\begin{proof}
    Because $V$ is finite-dimensional and $\dim V > 1$, there exist two vectors $v_{1}, v_{2}\in V$ such that they are linearly independent. Let $S', T'\in\mathcal{L}(\text{span}(v_{1}, v_{2}))$ such that $S'v_{1} = v_{2}, S'v_{2} = v_{1}$ and $T'v_{1} = v_{1}, T'v_{2} = 0$. According to Exercise~\ref{chapter3:sectionA:exercise13}, $S'$ and $T'$ can both be extended to linear maps $S$ and $T$ in $\mathcal{L}(V)$, respectively.
    \begin{align*}
        (ST)(v_{1}) & = S(Tv_{1}) = Sv_{1} = v_{2} \\
        (TS)(v_{1}) & = T(Sv_{1}) = Tv_{2} = 0
    \end{align*}

    So $ST\ne TS$. Hence there exists two linear maps in $\mathcal{L}(V)$ which are not commutative.
\end{proof}
\newpage

% chapter3:sectionA:exercise17
\begin{exercise}\label{chapter3:sectionA:exercise17}
    Suppose $V$ is finite-dimensional. Show that the only two-sided ideals of $\mathcal{L}(V)$ are $\{0\}$ and $\mathcal{L}(V)$.
        [A subspace $\mathcal{E}$ of $\mathcal{L}(V)$ is called a \textbf{two-sided ideal} of $\mathcal{L}(V)$ if $TE \in \mathcal{E}$ and $ET \in \mathcal{E}$ for all $E \in \mathcal{E}$ and all $T \in \mathcal{L}(V)$.]
\end{exercise}

\begin{proof}
    Suppose that $\mathcal{E}$ is a two-sided ideal of $\mathcal{L}(V)$ and $\mathcal{E}\ne \{0\}$. I will show that the identity map $\text{id}_{V}$ is in $\mathcal{E}$.

    Since $\mathcal{E}\ne \{0\}$, there exists $E\in\mathcal{E}$ such that $E$ is not the zero map. $E$ is not the zero map, so there exists a vector $v\ne 0$ such that $Ev\ne 0$. Let $v_{1}, \ldots, v_{n}$ be a basis of $V$. Since $v = x_{1}v_{1} + \cdots + x_{n}v_{n}$ for some scalars $x_{1}, \ldots, x_{n}$ and $v\ne 0$, there exists positive integer $k$ such that $x_{k}\ne 0$, then $v_{1}, \ldots, v_{k-1}, v, v_{k+1}, \ldots, v_{n}$ is also a basis of $V$. Therefore, without loss of generality, we can assume $v = v_{1}$. Let $w_{1} = Ev_{1}$. Similarly there exists a basis $w_{1}, \ldots, w_{n}$.

    Let's define linear maps $R_{i}$ and $S_{i}$ for every positive integer $i\in [\![ 1, n ]\!]$ as follows:
    \[
        R_{i}v_{k} = \begin{cases}
            v_{i} & \text{if $k = i$}  \\
            0     & \text{if $k\ne i$}
        \end{cases}
        \qquad
        S_{i}w_{k} = \begin{cases}
            v_{i} & \text{if $k = i$}  \\
            0     & \text{if $k\ne i$}
        \end{cases}
    \]

    For every positive integer $k\in [\![ 1, n ]\!]$
    \[
        \sum^{n}_{i=1}(S_{i}ER_{i})(v_{k}) = (S_{k}E)(v_{k}) = S_{k}(Ev_{k}) = S_{k}w_{k} = v_{k}.
    \]

    So $\sum^{n}_{i=1}S_{i}ER_{i}$ is the identity map $\text{id}_{V}$. Since $\text{id}_{V} = S_{i}ER_{i}\in\mathcal{E}$ for every positive integer $i\in [\![ 1, n ]\!]$, $\text{id}_{V}\in\mathcal{E}$. Moreover, for every linear map $T$, $\text{id}_{V}T\in\mathcal{E}$, which means $T\in\mathcal{E}$ for every $T\in\mathcal{L}(V)$. Therefore $\mathcal{E} = \mathcal{L}(V)$.

    Hence the only subspaces of $\mathcal{L}(V)$, which are two-side ideals, are $\{0\}$ and $\mathcal{L}(V)$.
\end{proof}
\newpage

\section{Null Spaces and Ranges}

% chapter3:sectionB:exercise1
\begin{exercise}
    Give an example of a linear map $T$ with $\dim \kernel{T} = 3$ and $\dim \range{T} = 2$.
\end{exercise}

\begin{proof}
    Here is one example. $T: \mathbb{R}^{3}\to \mathbb{R}^{3}$, where $T((x, y, z)) = (x, y, 0)$.
\end{proof}
\newpage

% chapter3:sectionB:exercise2
\begin{exercise}
    Suppose $S, T\in \mathcal{L}(V)$ are such that $\range{S}\subseteq \kernel{T}$. Prove that ${(ST)}^{2} = 0$.
\end{exercise}

\begin{proof}
    Let $v$ be a vector in $V$. ${(ST)}^{2}(v) = S(T(STv))$. Because $STv\in\range{S}\subseteq \kernel{T}$, then $T(STv) = 0$, and $S(T(STv)) = 0$. Hence ${(ST)}^{2} = 0$.
\end{proof}
\newpage

% chapter3:sectionB:exercise3
\begin{exercise}
    Suppose $v_{1}, \ldots, v_{m}$ is a list of vectors in $V$. Define $T\in \mathcal{L}(\mathbb{F}^{m}, V)$ by
    \[ T(z_{1}, \ldots, z_{m}) = z_{1}v_{1} + \cdots + z_{m}v_{m}. \]

    \begin{enumerate}[label={(\alph*)}]
        \item What property of $T$ corresponds to $v_{1}, \ldots, v_{m}$ spanning $V$?
        \item What property of $T$ corresponds to the list $v_{1}, \ldots, v_{m}$ being linearly independent?
    \end{enumerate}
\end{exercise}

\begin{proof}
    \begin{enumerate}[label={(\alph*)}]
        \item Surjectivity of $T$.
        \item Injectivity of $T$.
    \end{enumerate}
\end{proof}
\newpage

% chapter3:sectionB:exercise4
\begin{exercise}
    Show that $\{T \in \mathcal{L}(\mathbb{R}^{5}, \mathbb{R}^{4} ): \dim \kernel{T} > 2\}$ is not a subspace of $\mathcal{L}(\mathbb{R}^{5}, \mathbb{R}^{4})$.
\end{exercise}

\begin{proof}
    Let $S, T$ be linear maps in $\mathcal{L}(\mathbb{R}^{5}, \mathbb{R}^{4})$ such that
    \begin{align*}
        S(x_{1}, x_{2}, x_{3}, x_{4}, x_{5}) & = (x_{1}, x_{2}, 0, 0), \\
        T(x_{1}, x_{2}, x_{3}, x_{4}, x_{5}) & = (0, 0, x_{3}, x_{4}).
    \end{align*}

    According to this definition and the fundamental theorem of linear maps, $\dim \kernel{S} = \dim \kernel{T} = 5 - 2 = 3 > 2$. However
    \[
        (S + T)(x_{1}, x_{2}, x_{3}, x_{4}, x_{5}) = (x_{1}, x_{2}, x_{3}, x_{4})
    \]

    and $\dim\kernel{(S+T)} = 5 - 4 = 1 < 2$. So $\{T \in \mathcal{L}(\mathbb{R}^{5}, \mathbb{R}^{4} ): \dim \kernel{T} > 2\}$ is not closed under addition, so it is not a subspace of $\mathcal{L}(\mathbb{R}^{5}, \mathbb{R}^{4})$.
\end{proof}
\newpage

% chapter3:sectionB:exercise5
\begin{exercise}
    Give an example of $T \in \mathcal{L}(\mathbb{R}^{4})$ such that $\range{T} = \kernel{T}$.
\end{exercise}

\begin{proof}
    Let $T$ be a linear map in $\mathcal{L}(\mathbb{R}^{4})$ such that $T((x_{1}, x_{2}, x_{3}, x_{4})) = (x_{1} - x_{2}, x_{1} - x_{2}, x_{3} - x_{4}, x_{3} - x_{4})$.

    Then $\kernel{T} = \{ (a, a, b, b): a, b\in \mathbb{R} \}$, $\range{T} = \{ (a, a, b, b): a, b\in \mathbb{R} \}$.
\end{proof}
\newpage

% chapter3:sectionB:exercise6
\begin{exercise}
    Prove that there does not exist $T \in \mathcal{L}(\mathbb{R}^{5})$ such that $\range{T} = \kernel{T}$.
\end{exercise}

\begin{proof}
    According to the fundamental theorem of linear maps, $\dim \mathbb{R}^{5} = \dim\kernel{T} + \dim\range{T}$, so $5 = \dim\kernel{T} + \dim\range{T}$. Since $5$ is odd, then $\dim\kernel{T}\ne \dim\range{T}$, which means $\range{T}\ne \kernel{T}$.
\end{proof}
\newpage

% chapter3:sectionB:exercise7
\begin{exercise}
    Suppose $V$ and $W$ are finite-dimensional with $2 \leq \dim V \leq \dim W$. Show that $\{T \in \mathcal{L}(V, W) : T \text{ is not injective} \}$ is not a subspace of $\mathcal{L}(V, W)$.
\end{exercise}

\begin{proof}
    Let $v_{1}, v_{2}, \ldots, v_{n}$ be a basis of $V$, $w_{1}, w_{2}, \ldots, w_{n}, w_{n+1}, \ldots, w_{n+m}$ be a basis of $W$. According to the hypothesis, $n\geq 2, m\geq 0$.

    I define two linear maps $S, T$ in $\mathcal{L}(V, W)$ as follows:
    \[
        Sv_{k} = \begin{cases}
            w_{1} & \text{if $k = 1$}, \\
            0     & \text{otherwise}
        \end{cases}
        \qquad
        Tv_{k} = \begin{cases}
            0     & \text{if $k = 1$}, \\
            w_{k} & \text{otherwise}
        \end{cases}
    \]

    By this definition, $S, T$ are not injective. However, $S + T$ is injective. Hence $\{T \in \mathcal{L}(V, W) : T \text{ is not injective} \}$ is not a subspace of $\mathcal{L}(V, W)$, because it is not closed under addition.
\end{proof}
\newpage

% chapter3:sectionB:exercise8
\begin{exercise}
    Suppose $V$ and $W$ are finite-dimensional with $\dim V \geq \dim W \geq 2$. Show
    that $\{T \in \mathcal{L}(V, W) : T \text{ is not surjective}\}$ is not a subspace of $\mathcal{L}(V, W)$.
\end{exercise}

\begin{proof}
    Let $w_{1}, w_{2}, \ldots, w_{n}$ be a basis of $W$, $v_{1}, v_{2}, \ldots, v_{n}, v_{n+1}, \ldots, v_{n+m}$ be a basis of $V$. According to the hypothesis, $n\geq 2, m\geq 0$.

    I define two linear maps $S, T$ in $\mathcal{L}(V, W)$ as follows:
    \[
        Sv_{k} = \begin{cases}
            w_{1} & \text{if $k = 1$}, \\
            0     & \text{otherwise}
        \end{cases}
        \qquad
        Tv_{k} = \begin{cases}
            w_{k} & \text{if $1 < k\leq n$}, \\
            0     & \text{otherwise}
        \end{cases}
    \]

    By this definition, $S, T$ are not surjective. However,
    \[
        (S+T)(v_{k}) = \begin{cases}
            w_{k} & \text{if $1\leq k\leq n$}, \\
            0     & \text{otherwise}
        \end{cases}
    \]

    which means $S + T$ is surjective. Hence $\{T \in \mathcal{L}(V, W) : T \text{ is not surjective} \}$ is not a subspace of $\mathcal{L}(V, W)$, because it is not closed under addition.
\end{proof}
\newpage

% chapter3:sectionB:exercise9
\begin{exercise}\label{chapter3:sectionB:exercise9}
    Suppose $T \in \mathcal{L}(V, W)$ is injective and $v_{1}, \ldots, v_{n}$ is linearly independent in $V$. Prove that $Tv_{1} , \ldots, Tv_{n}$ is linearly independent in $W$.
\end{exercise}

\begin{proof}
    Suppose that $x_{1}Tv_{1} + \cdots + x_{n}Tv_{n} = 0$ is a linear combination of $0$. Then $T(x_{1}v_{1} + \cdots + x_{n}v_{n}) = 0$. Because $T$ is injective, it follows that $\kernel{T} = \{0\}$ and then $x_{1}v_{1} + \cdots + x_{n}v_{n} = 0$. Since $v_{1}, \ldots, v_{n}$ is linearly independent in $V$, $x_{1} = \cdots = x_{n} = 0$. Hence $Tv_{1} , \ldots, Tv_{n}$ is linearly independent in $W$.
\end{proof}
\newpage

% chapter3:sectionB:exercise10
\begin{exercise}
    Suppose $v_{1} ,\ldots, v_{n}$ spans $V$ and $T \in \mathcal{L}(V, W)$. Show that $Tv_{1} , \ldots, Tv_{n}$ spans $\range{T}$.
\end{exercise}

\begin{proof}
    Let $w$ be a vector in $\range{T}$, then there exists a vector $v\in V$ such that $Tv = w$. Because $v_{1} ,\ldots, v_{n}$ spans $V$, there exists scalars $x_{1}, \ldots, x_{n}$ such that $v = x_{1}v_{1} + \cdots + x_{n}v_{n}$. Then $w = Tv = x_{1}Tv_{1} + \cdots + x_{n}Tv_{n}$. Hence $Tv_{1}, \ldots, Tv_{n}$ spans $\range{T}$.
\end{proof}
\newpage

% chapter3:sectionB:exercise11
\begin{exercise}\label{chapter3:sectionB:exercise11}
    Suppose that $V$ is finite-dimensional and that $T \in \mathcal{L}(V, W)$. Prove that there exists a subspace $U$ of $V$ such that
    \[
        U \cap \kernel{T} = \{ 0 \}     \quad\text{and}\quad \range{T} = \{ Tu: u\in U \}.
    \]
\end{exercise}

\begin{proof}
    Let $v_{1}, \ldots, v_{n}$ be a basis of $\kernel{T}$. We extend this list to create a basis of $V$, and let it be
    \[ v_{1}, \ldots, v_{n}, v_{n+1}, \ldots, v_{n+m}. \]

    Let $U = \text{span}(v_{n+1}, \ldots, v_{n+m})$, then $U\cap \kernel{T} = \{0\}$, and $V = U\oplus \kernel{T}$. Let $v$ be a vector in $V$. According to the definition of direct sum of subspaces, there exist uniquely two vectors $v_{0}\in\kernel{T}$ and $u\in U$ such that $v = v_{0} + u$. $Tv = Tv_{0} + Tu = Tu$. Therefore $\range{T} = \{ Tu: u\in U \}$.

    Hence $U = \text{span}(v_{n+1}, \ldots, v_{n+m})$ is what we want to construct in this problem. $U$ is also a linear complement of $\kernel{T}$ in $V$.
\end{proof}
\newpage

% chapter3:sectionB:exercise12
\begin{exercise}
    Suppose $T$ is a linear map from $\mathbb{F}^{4}$ to $\mathbb{F}^{2}$ such that
    \[
        \kernel{T} = \{ (x_{1}, x_{2}, x_{3}, x_{4})\in\mathbb{F}^{4} : x_{1} = 5x_{2} \text{ and } x_{3} = 7x_{4} \}.
    \]

    Prove that $T$ is surjective.
\end{exercise}

\begin{proof}
    $\kernel{T} = \{ (5x_{2}, x_{2}, 7x_{4}, x_{4}) \}$. $(5x_{2}, x_{2}, 7x_{4}, x_{4}) = x_{2}(5, 1, 0, 0) + x_{4}(0, 0, 7, 1)$. $(5, 1, 0, 0)$ and $(0, 0, 7, 1)$ is a basis of $\kernel{T}$, so $\dim\kernel{T} = 2$. According to the fundamental theorem of linear maps, $\dim\mathbb{F}^{4} = \dim\kernel{T} + \dim\range{T}$, then $\dim\range{T} = 4 - 2 = 2 = \dim\mathbb{F}^{2}$. Therefore, $\range{T} = \mathbb{F}^{2}$, which implies $T$ is surjective.
\end{proof}
\newpage

% chapter3:sectionB:exercise13
\begin{exercise}
    Suppose $U$ is a three-dimensional subspace of $\mathbb{R}^{8}$ and that $T$ is a linear map from $\mathbb{R}^{8}$ to $\mathbb{R}^{5}$ such that $\kernel{T}= U$. Prove that $T$ is surjective.
\end{exercise}

\begin{proof}
    According to the fundamental theorem of linear maps, $\dim\mathbb{R}^{8} = \dim\kernel{T} + \dim\range{T}$, so $\dim\range{T} = 8 - \dim\kernel{T} = 8 - \dim U = 8 - 3 = 5 = \dim\mathbb{R}^{5}$. Therefore, $\range{T} = \mathbb{R}^{5}$, which implies $T$ is surjective.
\end{proof}
\newpage

% chapter3:sectionB:exercise14
\begin{exercise}
    Prove that there does not exist a linear map from $\mathbb{F}^{5}$ to $\mathbb{F}^{2}$ whose null space equals $\{(x_{1} , x_{2} , x_{3} , x_{4} , x_{5} ) \in \mathbb{F}^{5} : x_{1} = 3x_{2} \text{ and } x_{3} = x_{4} = x_{5} \}$.
\end{exercise}

\begin{proof}
    $\{(x_{1} , x_{2} , x_{3} , x_{4} , x_{5} ) \in \mathbb{F}^{5} : x_{1} = 3x_{2} \text{ and } x_{3} = x_{4} = x_{5} \} = \{ (3x_{2}, x_{2}, x_{3}, x_{3}, x_{3}) \}$.
    \[
        (3x_{2}, x_{2}, x_{3}, x_{3}, x_{3}) = x_{2}(3, 1, 0, 0, 0) + x_{3}(0, 0, 1, 1, 1)
    \]

    so the dimension of $\{(x_{1} , x_{2} , x_{3} , x_{4} , x_{5} ) \in \mathbb{F}^{5} : x_{1} = 3x_{2} \text{ and } x_{3} = x_{4} = x_{5} \}$ is $2$.

    Assume that there exists a linear map $T\in\mathcal{L}(\mathbb{F}^{5}, \mathbb{F}^{2})$ such that $\kernel{T} = \{(x_{1} , x_{2} , x_{3} , x_{4} , x_{5} ) \in \mathbb{F}^{5} : x_{1} = 3x_{2} \text{ and } x_{3} = x_{4} = x_{5} \}$. According to the fundamental theorem of linear maps, $\dim\range{T} = 5 - \dim\kernel{T} = 5 - 2 = 3$. However, this is not the case, because $\range{T}$ must be a subspace of $\mathbb{F}^{2}$.

    Hence there does not exist a linear map $T\in\mathcal{L}(\mathbb{F}^{5}, \mathbb{F}^{2})$ such that $\kernel{T} = \{(x_{1} , x_{2} , x_{3} , x_{4} , x_{5} ) \in \mathbb{F}^{5} : x_{1} = 3x_{2} \text{ and } x_{3} = x_{4} = x_{5} \}$.
\end{proof}
\newpage

% chapter3:sectionB:exercise15
\begin{exercise}\label{chapter3:sectionB:exercise15}
    Suppose there exists a linear map on $V$ whose null space and range are both finite-dimensional. Prove that $V$ is finite-dimensional.
\end{exercise}

\begin{proof}
    Let $v_{1}, \ldots, v_{n}$ be a basis of $\kernel{T}$, and $w_{1}, \ldots, w_{m}$ a basis of $\range{T}$. There exist vectors $u_{1}, \ldots, u_{m}$ such that $Tu_{1} = w_{1}, \ldots, Tu_{m} = w_{m}$.

    Let $v$ be a vector in $V$. There exist scalar $a_{1}, \ldots, a_{m}$ such that $Tv = a_{1}w_{1} + \cdots + a_{m}w_{m}$. Then
    \[
        Tv = a_{1}w_{1} + \cdots + a_{m}w_{m} = a_{1}Tu_{1} + \cdots + a_{m}Tu_{m} = T(a_{1}u_{1} + \cdots + a_{m}u_{m})
    \]

    it follows that $v - (a_{1}u_{1} + \cdots + a_{m}u_{m})\in \kernel{T}$. So there exist scalars $b_{1}, \ldots, b_{n}$ such that
    \[
        v - (a_{1}u_{1} + \cdots + a_{m}u_{m}) = b_{1}v_{1} + \cdots + b_{n}v_{n}.
    \]

    Therefore $v = a_{1}u_{1} + \cdots + a_{m}u_{m} + b_{1}v_{1} + \cdots + b_{n}v_{n}$, which means $u_{1}, \ldots, u_{m}, v_{1}, \ldots, v_{n}$ spans $V$. Hence $V$ is finite-dimensional.
\end{proof}
\newpage

% chapter3:sectionB:exercise16
\begin{exercise}
    Suppose $V$ and $W$ are both finite-dimensional. Prove that there exists an injective linear map from $V$ to $W$ if and only if $\dim V \leq \dim W$.
\end{exercise}

\begin{proof}
    $(\Rightarrow)$ There exists an injective linear map $T$ from $V$ to $W$. According to the fundamental theorem of linear maps, $\dim V = \dim\kernel{T} + \dim\range{T}$. Since $T$ is injective, $\dim\kernel{T} = 0$, and $\dim V = \dim\range{T}$. On the other hand, $\range{T}$ is a subspace of $W$, so $\dim\range{T}\leq \dim W$. Hence $\dim V\leq \dim W$.

    $(\Leftarrow)$ $\dim V\leq \dim W$. Let $v_{1}, \ldots, v_{n}$ be a basis of $V$, and $w_{1}, \ldots, w_{n}, w_{n+1}, \ldots, w_{n+m}$ be a basis of $W$. Let $T$ be the linear map that $Tv_{k} = w_{k}$ for every positive integer $k\in [\![ 1,n ]\!]$. Then $T$ is an injective linear map from $V$ to $W$.
\end{proof}
\newpage

% chapter3:sectionB:exercise17
\begin{exercise}
    Suppose $V$ and $W$ are both finite-dimensional. Prove that there exists a surjective linear map from $V$ to $W$ if and only if $\dim V \geq \dim W$.
\end{exercise}

\begin{proof}
    $(\Rightarrow)$ There exists a surjective linear map $T$ from $V$ to $W$. According to the fundamental theorem of linear maps, $\dim V = \dim\kernel{T} + \dim\range{T}$. Since $T$ is surjective, $\dim\range{T} = \dim W$. On the other hand, $\dim\range{T} = \dim V - \dim\kernel{T}\leq \dim V$, so $\dim V\geq \dim W$.

    $(\Leftarrow)$ $\dim V\geq \dim W$. Let $w_{1}, \ldots, w_{n}$ be a basis of $W$, and $v_{1}, \ldots, v_{n}, v_{n+1}, \ldots, v_{n+m}$ be a basis of $V$. Let $T$ be the linear map that $Tv_{k} = w_{k}$ for every positive integer $k\in [\![ 1,n ]\!]$ and $Tv_{k} = 0$ for every positive integer $k\in [\![ n+1, n+m ]\!]$. Then $T$ is a surjective linear map from $V$ to $W$.
\end{proof}
\newpage

% chapter3:sectionB:exercise18
\begin{exercise}
    Suppose $V$ and $W$ are finite-dimensional and that $U$ is a subspace of $V$. Prove that there exists $T\in \mathcal{L}(V, W)$ such that $\kernel{T} = U$ if and only if $\dim U \geq \dim V - \dim W$.
\end{exercise}

\begin{proof}
    $(\Rightarrow)$ There exists $T\in \mathcal{L}(V, W)$ such that $\kernel{T} = U$. According to the fundamental theorem of linear maps, $\dim V = \dim\kernel{T} + \dim\range{T}$. Since $\dim\kernel{T} = \dim U$ and $\dim\range{T}\leq \dim W$, $\dim V\leq \dim U + \dim W$, which means $\dim U\geq \dim V - \dim W$.

    $(\Leftarrow)$ $\dim U\geq \dim V - \dim W$. Since $U$ is a subspace of $V$, which is finite-dimensional, then $U$ is also finite-dimensional. Let $u_{1}, \ldots, u_{n}$ be a basis of $U$, extend this list to a basis $u_{1}, \ldots, u_{n}, v_{1}, \ldots, v_{m}$ of $V$. Because $\dim U\geq \dim V - \dim W$, $\dim W\geq (m + n) - n = m$. Let $w_{1}, \ldots, w_{m}, w_{m+1}, \ldots, w_{m+p}$ be a basis of $W$. Let $T$ be the linear map such that $Tu_{i} = 0$ for every positive integer $i\in[\![ 1,n ]\!]$, $Tv_{j} = w_{j}$ for every positive integer $i\in[\![ 1,m ]\!]$. Now I have to show that $\kernel{T} = U$.

    Due to the definition of $T$, it follows that $U\subseteq \kernel{T}$. Let $v$ be a vector in $\kernel{T}$, then $v = a_{1}u_{1} + \cdots + a_{n}u_{n} + b_{1}v_{1} + \cdots + b_{m}v_{m}$. $Tv = b_{1}Tv_{1} + \cdots + b_{m}Tv_{m} = b_{1}w_{1} + \cdots + b_{m}w_{m}$. Since $w_{1}, \ldots, w_{m}$ are linearly independent, $b_{1} = \cdots = b_{m} = 0$, so $v = a_{1}u_{1} + \cdots + a_{n}u_{n}\in U$. Therefore $\kernel{T}\subseteq U$. Hence $\kernel{T} = U$.
\end{proof}
\newpage

% chapter3:sectionB:exercise19
\begin{exercise}
    Suppose $W$ is finite-dimensional and $T\in\mathcal{L}(V, W)$. Prove that $T$ is injective if and only if there exists $S\in\mathcal{L}(W, V)$ such that $ST$ is the identity operator on $V$.
\end{exercise}

\begin{proof}
    $(\Rightarrow)$ There exists $S\in\mathcal{L}(W, V)$ such that $ST$ is the identity operator on $V$. Let $v\in\kernel{T}$. Since $ST = \text{id}_{V}$, then $(ST)(v) = v$. On the other hand, $(ST)(v) = S(Tv) = S(0) = 0$. So $v = 0$, which means $\kernel{T} = \{0\}$. Hence $T$ is injective.

    $(\Leftarrow)$ $T$ is injective, then $\dim\kernel{T} = 0$. $W$ is finite-dimensional, so $\range{T}$ is also finite-dimensional. According to Exercise~\ref{chapter3:sectionB:exercise15}, $V$ is finite-dimensional. On the other hand, $\dim V = \dim\kernel{T} + \dim\range{T} = \dim\range{T}\leq \dim W$.

    Let $v_{1}, \ldots, v_{n}$ be a basis of $V$. According to Exercise~\ref{chapter3:sectionB:exercise9}, $w_{1} = Tv_{1}, \ldots, w_{n} = Tv_{n}$ is linearly independent. Extend this list to a basis $w_{1}, \ldots, w_{n}, w_{n+1}, \ldots, w_{n+m}$ of $W$.

    I define a linear map $S$ from $W$ to $V$ as follows
    \[
        Sw_{k} = \begin{cases}
            v_{k} & \text{if $1\leq k\leq n$}, \\
            0     & \text{otherwise}.
        \end{cases}
    \]

    Then $ST$ is the identity operator on $V$.
\end{proof}
\newpage

% chapter3:sectionB:exercise20
\begin{exercise}
    Suppose $V$ is finite-dimensional and $T\in\mathcal{L}(V, W)$. Prove that $T$ is surjective if and only if there exists $S\in\mathcal{L}(W, V)$ such that $TS$ is the identity operator on $W$.
\end{exercise}

\begin{proof}
    $(\Rightarrow)$ There exists $S\in\mathcal{L}(W, V)$ such that $TS$ is the identity operator on $W$. Let $w\in W$. Since $TS = \text{id}_{W}$, then $(TS)(w) = w$, and $T(Sw) = w$. So $w\in \range{T}$, and $\range{T} = W$. Therefore $T$ is surjective.

    $(\Leftarrow)$ $T$ is surjective, then $\range{T} = W$. According to the proof of the fundamental theorem of linear maps, if $u_{1}, \ldots, u_{m}$ is a basis of $\kernel{T}$, the extended list $u_{1}, \ldots, u_{m}, v_{1}, \ldots, v_{n}$ is a basis of of $V$, then $w_{1} = Tv_{1}, \ldots, w_{n} = Tv_{n}$ is a basis of $\range{T}$.

    I define a linear map $S$ from $W$ to $V$ by $Sw_{k} = v_{k}$ for every positive integer $k\in[\![ 1, n ]\!]$. Then $TS$ is the identity operator on $W$.
\end{proof}
\newpage

% chapter3:sectionB:exercise21
\begin{exercise}
    Suppose $V$ is finite-dimensional, $T \in \mathcal{L}(V, W)$, and $U$ is a subspace of $W$. Prove that $\{v \in V : Tv \in U\}$ is a subspace of $V$ and
    \[
        \dim\{ v\in V : Tv\in U \} = \dim \kernel{T} + \dim (U\cap \range{T}).
    \]
\end{exercise}

\begin{proof}
    Let $X = \{v \in V : Tv \in U\}$. Because $T0 = 0\in U$, $0\in X$. If $v\in X$, then $Tv\in U$, and $T(\lambda v)\in U$ for every $\lambda\in\mathbb{F}$. If $v_{1}, v_{2}\in X$, then $T(v_{1} + v_{2}) = Tv_{1} + Tv_{2}\in U$. So $X$ contains $0$, is closed under addition and scalar multiplication. Therefore $X$ is a subspace of $V$.

    Due to the definition of null space and $X$, it follows that $\kernel{T}$ is a subspace of $X$. Let $S$ be the linear map from $X$ to $U$ that $Su = Tu$ for every $u\in U$. Then $\kernel{T} = \kernel{S}$.

    $\range{S}$ is a subspace of $U\cap \range{T}$. For each vector $w$ in $U\cap \range{T}$, there exists a vector $v\in V$ such that $Tv = w$. On the other hand, since $w\in U$, then $v\in U$. So $Sv = w$, and it follows that $U\cap \range{T}$ is a subspace of $\range{S}$. Then $\range{S} = U\cap \range{T}$.

    According to the fundamental theorem of linear map,
    \[
        \dim X = \dim\kernel{S} + \dim\range{S} = \dim\kernel{T} + \dim (U\cap\range{T}).\qedhere
    \]
\end{proof}
\newpage

% chapter3:sectionB:exercise22
\begin{exercise}
    Suppose $U$ and $V$ are finite-dimensional vector spaces and $S \in \mathcal{L}(V, W)$ and $T \in \mathcal{L}(U, V)$. Prove that
    \[
        \dim\kernel{ST} \leq \dim\kernel{S} + \dim\kernel{T}.
    \]
\end{exercise}

\begin{proof}
    \[
        \begin{CD}
            U @>T>>     V @>S>>     W
        \end{CD}
    \]

    Because $U, V$ are finite-dimensional, then so are $\kernel{T}$, $\range{T}$, $\kernel{S}$, $\range{S}$.

    According to the fundamental theorem of linear maps,
    \[
        \dim\kernel{ST} = \dim U - \dim\range{ST} = \dim \kernel{T} + \dim\range{T} - \dim\range{ST}.
    \]

    and
    \[
        \dim\range{T} = \dim \kernel{S\vert_{\range{T}}} + \dim\range{ST} = \dim (\kernel{S}\cap\range{T}) + \dim\range{ST}.
    \]

    On the other hand, $\dim (\kernel{S}\cap\range{T}) \leq \dim\kernel{S}$ (where $S\vert_{\range{T}}$ is the linear map $S$ restricted on $\range{T}$ instead of the entire $V$). Therefore
    \[
        \dim\kernel{ST} \leq \dim\kernel{T} + \dim\kernel{S}.
    \]

    The equality holds if and only if $\kernel{S}\subseteq \range{T}$.
\end{proof}
\newpage

% chapter3:sectionB:exercise23
\begin{exercise}
    Suppose $U$ and $V$ are finite-dimensional vector spaces and $S \in \mathcal{L}(V, W)$ and $T \in \mathcal{L}(U, V)$. Prove that
    \[
        \dim\range{ST} \leq \min\{\dim\range{S}, \dim\range{T}\}.
    \]
\end{exercise}

\begin{proof}
    \[
        \begin{CD}
            U @>T>>     V @>S>>     W
        \end{CD}
    \]

    Because $U, V$ are finite-dimensional, then so are $\kernel{T}$, $\range{T}$, $\kernel{S}$, $\range{S}$.

    $ST\in\mathcal{L}(U, W)$. If $w\in\range{ST}$, then there exists $u\in U$ such that $(ST)(u) = w$. So $S(Tu) = w$, and $w$ is also in $\range{S}$. So $\range{ST}$ is a subspace of $\range{S}$, and $\dim\range{ST}\leq \dim\range{S}$.

    According to the fundamental theorem of linear maps,
    \[
        \dim\range{T} = \dim \kernel{S\vert_{\range{T}}} + \dim\range{ST} = \dim (\kernel{S}\cap\range{T}) + \dim\range{ST} \geq \dim\range{ST}
    \]

    So $\dim\range{ST}\leq \dim\range{T}$. Hence
    \[
        \dim\range{ST}\leq \min\{ \dim\range{S}, \dim\range{T} \}.\qedhere
    \]
\end{proof}
\newpage

% chapter3:sectionB:exercise24
\begin{exercise}
    \begin{enumerate}[label={(\alph*)}]
        \item Suppose $\dim V = 5$ and $S, T \in \mathcal{L}(V)$ are such that $ST = 0$. Prove that $\dim \range{TS} \leq 2$.
        \item Give an example of $S, T \in \mathcal{L}(\mathbb{F}^{5})$ with $ST = 0$ and $\dim\range{TS} = 2$.
    \end{enumerate}
\end{exercise}

\begin{proof}
    Unsolved.
\end{proof}
\newpage

% chapter3:sectionB:exercise25
\begin{exercise}
    Suppose that $W$ is finite-dimensional and $S, T \in \mathcal{L}(V, W)$. Prove that $\kernel{S} \subseteq \kernel{T}$ if and only if there exists $E \in \mathcal{L}(W)$ such that $T = ES$.
\end{exercise}

\begin{proof}
    $(\Rightarrow)$ There exists $E\in\mathcal{L}(W)$ such that $T = ES$. Let $v$ be a vector in $\kernel{S}$. Then $Tv = (ES)(v) = E(Sv) = E0 = 0$. So $v$ is also in $\kernel{T}$. Therefore $\kernel{S}\subseteq\kernel{T}$.

    $(\Leftarrow)$ $\kernel{S}\subseteq\kernel{T}$. Since $W$ is finite-dimensional, then so are $\range{S}$ and $\range{T}$.

    \begin{enumerate}[label={\textbf{Step \arabic*.}},itemindent={1cm}]
        \item Construct a linear complement of $\kernel{S}$ in $\kernel{T}$.

              Let $Sv_{1}, \ldots, Sv_{n}$ be a basis of $\range S\vert_{\kernel{T}}$. Let $0 = a_{1}v_{1} + \cdots + a_{n}v_{n}$ be a linear combination of $0$ in $V$. Then $0 = S(a_{1}v_{1} + \cdots + a_{n}v_{n}) = a_{1}Sv_{1} + \cdots + a_{n}Sv_{n}$. Because $Sv_{1}, \ldots, Sv_{n}$ is linearly independent, it follows that $a_{1} = \cdots = a_{n} = 0$. So $v_{1}, \ldots, v_{n}$ is linearly independent.

              Let $v$ be a vector in $\kernel{T}$. There exist scalars $b_{1}, \ldots, b_{n}$ such that $Sv = b_{1}Sv_{1} + \cdots + b_{n}Sv_{n}$. So $S(v - b_{1}v_{1} - \cdots - b_{n}v_{n}) = 0$, which means $v$ is the sum of $b_{1}v_{1} + \cdots + b_{n}v_{n}$ and a vector in $\kernel{S}$. Therefore $\kernel{T} = \kernel{S} + \text{span}(v_{1}, \ldots, v_{n})$.

              A vector $x_{1}v_{1} + \cdots + x_{n}v_{n}$ in $\text{span}(v_{1}, \ldots, v_{n})$ is in $\kernel{S}$ if and only if $x_{1}Sv_{1} + \cdots + x_{n}Sv_{n} = 0$. On the other hand, $x_{1}Sv_{1} + \cdots + x_{n}Sv_{n} = 0$ if and only if $x_{1} = \cdots = x_{n} = 0$. So $\kernel{S}\cap \text{span}(v_{1}, \ldots, v_{n}) = \{0\}$.

              Hence $\kernel{T} = \kernel{S}\oplus\text{span}(v_{1}, \ldots, v_{n})$.
        \item Construct a linear complement of $\kernel T$ in $V$.

              Let $Tu_{1}, \ldots, Tu_{m}$ be a basis of $\range{T}$.

              Let $0 = a_{1}u_{1} + \cdots + a_{n}u_{n}$ be a linear combination of $0$ in $V$. Then
              \[
                  0 = T0 = T(a_{1}u_{1} + \cdots + a_{n}u_{n}) = a_{1}Tu_{1} + \cdots + a_{n}Tu_{n}.
              \]

              Since $Tu_{1}, \ldots, Tu_{m}$ is linearly independent, $a_{1} = \cdots = a_{m} = 0$. So $u_{1}, \ldots, u_{m}$ is linearly independent.

              $x_{1}u_{1} + \cdots + x_{m}u_{m}$ is in $\kernel{T}$ if and only if $T(x_{1}u_{1} + \cdots + x_{m}u_{m}) = 0$.
              \[
                  x_{1}Tu_{1} + \cdots + x_{m}Tu_{m} = T(x_{1}u_{1} + \cdots + x_{m}u_{m}) = 0.
              \]

              $x_{1}Tu_{1} + \cdots + x_{m}Tu_{m} = 0$ if and only if $x_{1} = \cdots = x_{m} = 0$. So $\kernel{T}\cap\text{span}(u_{1}, \ldots, u_{m}) = \{0\}$.

              Let $v$ be a vector in $V$, then there exist scalars $a_{1}, \ldots, a_{m}$ such that $Tv = a_{1}Tu_{1} + \cdots + a_{m}Tu_{m}$. So
              \[
                  Tv = a_{1}Tu_{1} + \cdots + a_{m}Tu_{m} = T(a_{1}u_{1} + \cdots + a_{m}u_{m}).
              \]

              It follows that $v - (a_{1}u_{1} + \cdots + a_{m}u_{m})$ is in $\kernel{T}$. So $V = \kernel{T} + \text{span}(u_{1}, \ldots, u_{m})$.

              Because $V = \kernel{T} + \text{span}(u_{1}, \ldots, u_{m})$ and $\kernel{T}\cap \text{span}(u_{1}, \ldots, u_{m}) = \{0\}$, we conclude that $V = \kernel{T}\oplus \text{span}(u_{1}, \ldots, u_{m})$.
        \item Construct a linear map $E$ in $\mathcal{L}(W)$.

              Due to \textbf{Step 1} and \textbf{Step 2}
              \[
                  V = \underbrace{\kernel{S} \oplus \text{span}(v_{1}, \ldots, v_{n})}_{\kernel{T}} \oplus \text{span}(u_{1}, \ldots, u_{m}).
              \]

              On the other hand, $Sv_{1}, \ldots, Sv_{n}, Su_{1}, \ldots, Su_{m}$ is a basis of $\range{S}$, because, if $x_{1}Sv_{1} + \cdots + x_{n}Sv_{n} + y_{1}Su_{1} + \cdots + y_{m}Su_{m} = 0$ is a linear combination of $0$ in $\range{S}$, then $S(x_{1}v_{1} + \cdots + x_{n}v_{n} + y_{1}u_{1} + \cdots + y_{m}u_{m}) = 0$. But $\kernel{S}\cap \text{span}(v_{1}, \ldots, v_{n}, u_{1}, \ldots, u_{m}) = \{0\}$, so $x_{1}v_{1} + \cdots + x_{n}v_{n} + y_{1}u_{1} + \cdots + y_{m}u_{m} = 0$, which implies $x_{1} = \cdots = x_{n} = 0$, $y_{1} = \cdots = y_{m} = 0$ because the list $v_{1}, \ldots, v_{n}, u_{1}, \ldots, u_{m}$ is linearly independent.

              I define the linear map $E$ in $\mathcal{L}(W)$ as follows:
              \[
                  E(Sv_{i}) = 0\qquad E(Su_{j}) = Tu_{j}.
              \]

              Let $v$ be a vector in $V$. There exist $v_{0}$ in $\kernel{S}$ and scalars $a_{1}, \ldots, a_{n}, b_{1}, \ldots, b_{m}$ such that $v = v_{0} + a_{1}v_{1} + \cdots + a_{n}v_{n} + b_{1}u_{1} + \cdots + b_{m}u_{m}$. Note that $Tv_{0} = Sv_{0} = 0$ because $\kernel S\subseteq \kernel T$ and $Tv_{1} = \cdots = Tv_{n} = 0$.
              \begin{align*}
                  (ES)(v) & = E(Sv_{0} + a_{1}Sv_{1} + \cdots + a_{n}Sv_{n} + b_{1}Su_{1} + \cdots + b_{m}Su_{m})                 \\
                          & = E(Sv_{0}) + (a_{1}E(Sv_{1}) + \cdots + a_{n}E(Sv_{n})) + (b_{1}E(Su_{1}) + \cdots + b_{m}E(Su_{m})) \\
                          & = 0 + (0 + \cdots + 0) + (b_{1}Tu_{1} + \cdots + b_{m}Tu_{m})                                         \\
                          & = Tv_{0} + (a_{1}Tv_{1} + \cdots + a_{n}Tv_{n}) + (b_{1}Tu_{1} + \cdots + b_{m}Tu_{m})                \\
                          & = T(v_{0} + a_{1}v_{1} + \cdots + a_{n}v_{n} + b_{1}u_{1} + \cdots + b_{m}u_{m})                      \\
                          & = Tv.
              \end{align*}

              Hence $T = ES$.\qedhere
    \end{enumerate}
\end{proof}
\newpage

% chapter3:sectionB:exercise26
\begin{exercise}
    Suppose that $V$ is finite-dimensional and $S, T \in \mathcal{L}(V, W)$. Prove that $\range{S} \subseteq \range{T}$ if and only if there exists $E \in \mathcal{L}(V)$ such that $S = TE$.
\end{exercise}

\begin{proof}
    $(\Rightarrow)$ There exists $E \in \mathcal{L}(V)$ such that $S = TE$. Let $w$ be a vector in $\range{S}$, then there exists a vector $v$ in $V$ such that $Sv = w$. So $(TE)(v) = w$, and $T(Ev) = w$. Therefore $w$ is also in $\range{T}$. Hence $\range{S}\subseteq\range{T}$.

    $(\Leftarrow)$ $\range{S} \subseteq \range{T}$.

    According to the fundamental theorem of linear maps, $\range{S}$ and $\range{T}$ are finite-dimensional.

    Let $Su_{1}, \ldots, Su_{n}$ be a basis of $\range{S}$.

    $u_{1}, \ldots, u_{n}$ is linearly independent. Extend the list $u_{1}, \ldots, u_{n}$ to create a basis of $V$ and let it be
    \[
        u_{1}, \ldots, u_{n}, u_{n+1}, \ldots, u_{n+m}, u_{n+m+1}, \ldots, u_{n+m+p}.
    \]

    Since $\range{S}\subseteq \range{T}$, there exist vectors $v_{k}$ such that $Su_{k} = Tv_{k}$ for every positive integer $k\in [\![ 1, n+m+p ]\!]$.

    I define the linear map $E$ in $\mathcal{L}(V)$ as follows: $Eu_{k} = v_{k}$ for every positive integer $k\in [\![ 1, n+m+p ]\!]$.

    Then $(TE)(u_{k}) = T(Eu_{k}) = Tv_{k} = Su_{k}$ for every positive integer $k\in [\![ 1, n+m+p ]\!]$.

    Hence $S = TE$.\qedhere
\end{proof}
\newpage

% chapter3:sectionB:exercise27
\begin{exercise}
    Suppose $P \in \mathcal{L}(V)$ and $P^{2} = P$. Prove that $V = \kernel{P}\oplus \range{P}$.
\end{exercise}

\begin{proof}
    Let $v$ be a vector in $V$. $v = (v - Pv) + Pv$. On the other hand, $P(v - Pv) = Pv - P^{2}v = 0$. So $V = \kernel{P}\oplus \range{P}$.

    Let $w$ be a vector in $\kernel{P}\cap\range{P}$. Then there exists vector $v$ in $V$ such that $Pv = w$. On the other hand, $Pw = 0$ because $w\in\kernel{P}$. So $w = Pv = P^{2}v = Pw = 0$. Therefore $\kernel{P}\cap\range{P} = \{0\}$.

    Hence $V = \kernel{P}\oplus\range{P}$.
\end{proof}
\newpage

% chapter3:sectionB:exercise28
\begin{exercise}
    Suppose $D \in \mathcal{L}(\mathcal{P}(\mathbb{R}))$ is such that $\deg Dp = (\deg p) - 1$ for every non-constant polynomial $p \in \mathcal{P}(\mathbb{R})$. Prove that $D$ is surjective.
\end{exercise}

\begin{proof}
    Let $a$ be a polynomial of degree $1$, let $c$ be a constant polynomial, then $a + c$ is a polynomial of degree $1$. $D(a + c)$ is a constant polynomial, because $\deg D(a+c) = \deg (a + c) - 1 = 0$. On the other hand, $D(a + c) = Da + Dc$, so $Dc$ is a constant polynomial.

    Suppose that $Dc\ne 0$. Because $\deg Da = 0$, it follows that $Da\ne 0$.
    \[
        D\left(\frac{-Dc}{Da}a + c\right) = \frac{-Dc}{Da}\cdot Da + Dc = 0.
    \]

    It follows that $\deg D\left(\frac{-Dc}{Da}a + c\right) = -\infty \ne 0 = \deg\left(\frac{-Dc}{Da}a + c\right) - 1$. So the assumption $Dc\ne 0$ is false. Therefore $Dc = 0$. So $0$ is in $\range{D}$.

    I will prove the following statement by using mathematical induction: for each nonnegative integer $n$, every polynomial of degree $n$ in $\mathcal{L}(\mathcal{P}(\mathbb{R}))$ is in $\range{D}$.

    When $n = 0$. Let $c_{0}$ be a nonzero constant polynomial. Let $c_{1}$ be a polynomial of degree $1$. $\deg Dc_{1} = 0$, so there exist a nonzero constant polynomial $d_{0}$ such that $Dc_{1} = d_{0}$. $D\left(\frac{c_{0}}{d_{0}}c_{1}\right) = \frac{c_{0}}{d_{0}}\cdot d_{0} = c_{0}$. So $c_{0}\in\range{D}$.

    Assume that for every nonnegative integer $n\leq k$, every polynomial of degree $k$ is in $\range{D}$. Let $p_{k+1}$ be a polynomial of degree $(k+1)$, $p_{k+2}$ be a polynomial of degree $(k+2)$, $q_{k+1} = Dp_{k+2}$. Let $a_{k+1}$ and $b_{k+1}$ be the leading coefficients of $p_{k+1}$ and $q_{k+1}$. Since
    \[
        \deg\left(\frac{1}{a_{k+1}}p_{k+1} - \frac{1}{b_{k+1}}q_{k+1}\right) \leq k
    \]

    then $\frac{1}{a_{k+1}}p_{k+1} - \frac{1}{b_{k+1}}q_{k+1}$ is in $\range{D}$. Together with $q_{k+1}$ being in $\range{D}$, we conclude that $p_{k+1}$ is also in $\range{D}$.

    Due to the principle of mathematical induction, every nonzero polynomial is in $\range{D}$.

    Because the zero polynomial and every nonzero polynomial are in $\range{D}$, it follows that every polynomial is in $D$. Thus $D$ is surjective.
\end{proof}
\newpage

% chapter3:sectionB:exercise29
\begin{exercise}
    Suppose $p \in \mathcal{P}(\mathbb{R})$. Prove that there exists a polynomial $q \in \mathcal{P}(\mathbb{R})$ such that $5q'' + 3q' = p$.
\end{exercise}

\begin{proof}
    If $p$ is the zero polynomial, then $q(x) = 1$ satisfies.

    If $p$ is a nonzero polynomial, let $p: x\mapsto a_{0} + a_{1}x + \cdots + a_{n}x^{n}$ where $a_{n}\ne 0$. Any polynomial $q$ that satisfies the differential equation must have degree $(n+1)$.

    Let $q(x) = b_{0} + b_{1}x + \cdots + b_{n+1}x^{n+1}$. The coefficient of $x^{k}$ in $5q''(x) + 3q'(x)$ where $k < n$ is
    \[
        5(k+2)(k+1)b_{k+2} + 3(k+1)b_{k+1}.
    \]

    The coefficient of $x^{k}$ in $5q''(x) + 3q'(x)$ where $k = n$ is
    \[
        (n+1)b_{n+1}.
    \]

    We obtain a system of $(n+1)$ linear equations:
    \begin{align*}
        (n+1)b_{n+1}                       & = a_{n} \\
        5(k+2)(k+1)b_{k+2} + 3(k+1)b_{k+1} & = a_{k}
    \end{align*}

    This system of linear equations has more unknowns than equations (there are $(n+2)$ unknowns and $(n+1)$ equations), so it has at least one solution. Therefore there exists a polynomial $q\in\mathcal{P}(\mathbb{R})$ such that $5q'' + 3q' = p$.
\end{proof}
\newpage

% chapter3:sectionB:exercise30
\begin{exercise}\label{chapter3:sectionB:exercise30}
    Suppose $\varphi \in \mathcal{L}(V, \mathbb{F})$ and $\varphi \ne 0$. Suppose $u \in V$ is not in $\kernel{\varphi}$. Prove that
    \[
        V = \kernel{\varphi} \oplus \{ au : a\in\mathbb{F} \}.
    \]
\end{exercise}

\begin{proof}
    Let $v$ be a vector in $V$. $\varphi u\ne 0$ so $\varphi u$ is a basis of $\mathbb{F}$. So there exists a scalar $\lambda\in\mathbb{F}$ such that $\varphi v = \lambda\cdot \varphi u$. So $\varphi(v - \lambda u) = 0$, which implies $v - \lambda u$ is in $\kernel{\varphi}$. So $V = \kernel{\varphi} + \text{span}(u)$.

    Let $v_{0}$ be a vector in $\kernel{\varphi}\cap\text{span}(u)$. So there exists s scalar $\lambda_{0}$ such that $v_{0} = \lambda_{0}u$. $\varphi v_{0} = 0$ and $\varphi v_{0} = \lambda_{0}\cdot \varphi u$. So $\lambda_{0} = 0$. Therefore $v_{0} = 0$, and $\kernel{\varphi}\cap\text{span}(u) = \{0\}$.

    Hence $V = \kernel{\varphi} \oplus \text{span}(u)$.
\end{proof}
\newpage

% chapter3:sectionB:exercise31
\begin{exercise}
    Suppose $V$ is finite-dimensional, $X$ is a subspace of $V$, and $Y$ is a finite-dimensional subspace of $W$. Prove that there exists $T \in \mathcal{L}(V, W)$ such that $\kernel{T} = X$ and $\range{T} = Y$ if and only if $\dim X + \dim Y = \dim V$.
\end{exercise}

\begin{proof}
    $(\Rightarrow)$ There exists $T \in \mathcal{L}(V, W)$ such that $\kernel{T} = X$ and $\range{T} = Y$.

    According to the fundamental theorem of linear maps, $\dim V = \dim X + \dim Y$.

    $(\Leftarrow)$ $\dim V = \dim X + \dim Y$.

    Let $v_{1}, \ldots, v_{n}$ be a basis of $X$. Extend this list to create a basis of $V$, and let it be $v_{1}, \ldots, v_{n}, v_{n+1}, \ldots, v_{n+m}$.

    Let $w_{1}, \ldots, w_{m}$ be a basis of $Y$. I define the linear map $T$ from $V$ to $W$ as follows:
    \[
        Tv_{k} = \begin{cases}
            0       & \text{if $1\leq k\leq n$} \\
            w_{k-n} & \text{otherwise}
        \end{cases}
    \]

    From this definition, and the linear independence of $w_{1}, \ldots, w_{m}$, it follows that $\range{T} = Y$ and $\kernel{T} = X$.
\end{proof}
\newpage

% chapter3:sectionB:exercise32
\begin{exercise}
    Suppose $V$ is finite-dimensional with $\dim V > 1$. Show that if $\varphi: \mathcal{L}(V) \to \mathbb{F}$ is a linear map such that $\varphi(ST) = \varphi(S)\varphi(T)$ for all $S, T \in \mathcal{L}(V)$, then $\varphi = 0$.
\end{exercise}

\begin{proof}
    Let $v_{1}, v_{2}, \ldots, v_{n}$ be a basis of $V$.

    Let $S$ be a linear map in $\kernel{\varphi}$, $T$ a linear map in $\mathcal{L}(V)$. $\varphi(ST) = \varphi(S)\varphi(T) = 0$, $\varphi(TS) = \varphi(T)\varphi(S) = 0$. So $ST$, $TS$ are also in $\kernel{\varphi}$. Therefore $\varphi{T}$ is a two-sided ideal. According to Exercise~\ref{chapter3:sectionA:exercise17}, $\kernel{\varphi}$ is either $\{0\}$ or $\mathcal{L}(V)$.

    Let $R$ be the linear map in $\mathcal{L}(V)$ that $Rv_{1} = v_{2}$, $Rv_{i} = 0$ for every positive integer $i\in[\![ 2, n ]\!]$, then $R^{2} = 0$. So $\varphi(R^{2}) = \varphi(R)\varphi(R) = 0$, and $\varphi(R) = 0$. Since $R\ne 0$, then $\kernel{\varphi}\ne \{0\}$. Hence $\kernel{\varphi} = \mathcal{L}(V)$, which implies $\varphi = 0$.
\end{proof}
\newpage

% chapter3:sectionB:exercise33
\begin{exercise}
    Suppose that $V$ and $W$ are real vector spaces and $T \in \mathcal{L}(V, W)$. Define $T_{\mathbb{C}}: V_{\mathbb{C}} \to W_{\mathbb{C}}$ by
    \[
        T_{\mathbb{C}}(u + \iota v) = Tu + \iota Tv
    \]

    for all $u, v\in V$.
    \begin{enumerate}[label={(\alph*)}]
        \item Show that $T_{\mathbb{C}}$ is a (complex) linear map from $V_{\mathbb{C}}$ to $W_{\mathbb{C}}$.
        \item Show that $T_{\mathbb{C}}$ is injective if and only if $T$ is injective.
        \item Show that $\range T_{\mathbb{C}} = W_{\mathbb{C}}$ if and only if $\range T = W$.
    \end{enumerate}
\end{exercise}

\begin{proof}
    \begin{enumerate}[label={(\alph*)}]
        \item \begingroup\allowdisplaybreaks
              \begin{align*}
                  T_{\mathbb{C}}((u_{1} + \iota v_{1}) + (u_{2} + \iota v_{2})) & = T_{\mathbb{C}}((u_{1} + u_{2}) + \iota (v_{1} + v_{2}))                    \\
                                                                                & = T(u_{1} + u_{2}) + \iota T(v_{1} + v_{2})                                  \\
                                                                                & = (Tu_{1} + Tu_{2}) + \iota (Tv_{1} + Tv_{2})                                \\
                                                                                & = (Tu_{1} + \iota Tv_{1}) + (Tu_{2} + \iota Tv_{2})                          \\
                                                                                & = T_{\mathbb{C}}(u_{1} + \iota v_{1}) + T_{\mathbb{C}}(u_{2} + \iota v_{2}), \\
                  T_{\mathbb{C}}((a + b\iota)(u + \iota v))                     & = T_{\mathbb{C}}((au - bv) + \iota (av + bu))                                \\
                                                                                & = T(au - bv) + \iota T(av + bu)                                              \\
                                                                                & = (T(au) + \iota^{2} T(bv)) + (\iota T(av) + \iota T(bu))                    \\
                                                                                & = (T(au) + \iota T(bu)) + \iota (T(av) + \iota T(bv))                        \\
                                                                                & = (a + b\iota) Tu + (a + b\iota)\iota Tv                                     \\
                                                                                & = (a + b\iota) (Tu + \iota Tv)                                               \\
                                                                                & = (a + b\iota) T_{\mathbb{C}}(u + \iota v).
              \end{align*}
              \endgroup

              Thus $T_{\mathbb{C}}$ is a linear map.
        \item $(\Rightarrow)$ $T$ is injective.

              $Tu = Tv = 0$ if and only if $u = v = 0$. So $T_{\mathbb{C}}(u + \iota v) = 0$ if and only if $u + \iota v = 0 + \iota 0$. Hence $T_{\mathbb{C}}$ is injective.

              $(\Leftarrow)$ $T_{\mathbb{C}}$ is injective.

              $T_{\mathbb{C}}(u + \iota v) = 0$ if and only if $u + \iota v = 0$. If $Tu = 0$, then $0 = Tu + \iota T0 = T_{\mathbb{C}}(u + \iota 0)$. $T_{\mathbb{C}}(u + \iota 0) = 0$ if and only if $u = 0$. Hence $T$ is injective.
        \item $(\Rightarrow)$ $T$ is surjective.

              Let $w + \iota z$ be a vector in $W_{\mathbb{C}}$. There exist vectors $u, v$ in $V$ such that $Tu = w$, $Tv = z$. $T_{\mathbb{C}}(u + \iota v) = Tu + \iota Tv = w + \iota z$. Hence $T_{\mathbb{C}}$ is surjective.

              $(\Leftarrow)$ $T_{\mathbb{C}}$ is surjective.

              Let $w$ be a vector in $W$. There exists a vector $u + \iota v$ in $V_{\mathbb{C}}$ such that $T_{\mathbb{C}}(u + \iota v) = w + \iota 0$.

              So $w + \iota 0 = T_{\mathbb{C}}(u + \iota v) = Tu + \iota Tv$. Therefore $w = Tu$ and $0 = Tv$. Hence $T$ is surjective.
    \end{enumerate}
\end{proof}
\newpage

\section{Matrices}

% chapter3:sectionC:exercise1
\begin{exercise}
    Suppose $T \in \mathcal{L}(V, W)$. Show that with respect to each choice of bases of $V$ and $W$, the matrix of $T$ has at least $\dim \range{T}$ nonzero entries.
\end{exercise}

\begin{proof}
    Let $v_{1}, \ldots, v_{n}$ be a basis of $V$, $w_{1}, \ldots, w_{m}$ be a basis of $W$, $\mathcal{M}(T)$ be the matrix of $T$ with respect to these two bases.

    $Tv_{i}$ is a linear combination of $w_{1}, \ldots, w_{m}$ where the coefficients are the $i$th column of $\mathcal{M}(T)$. The list $Tv_{1}, \ldots, Tv_{n}$ spans $\range{T}$. So there are $\dim\range{T}$ vectors in $Tv_{1}, \ldots, Tv_{n}$ that are linearly independent, and there are at least $\dim\range{T}$ columns of $\mathcal{M}(T)$ that are nonzero. Therefore $\mathcal{M}(T)$ has at least $\dim\range{T}$ nonzero entries.
\end{proof}
\newpage

% chapter3:sectionC:exercise2
\begin{exercise}
    Suppose $V$ and $W$ are finite-dimensional and $T \in \mathcal{L}(V, W)$. Prove that $\dim \range{T} = 1$ if and only if there exist a basis of $V$ and a basis of $W$ such that with respect to these bases, all entries of $\mathcal{M}(T)$ equal $1$.
\end{exercise}

\begin{proof}
    $(\Rightarrow)$ There exist bases $v_{1}, \ldots, v_{n}$ of $V$, $w_{1}, \ldots, w_{m}$ of $W$, such that all entries of $\mathcal{M}(T)$ equal $1$.

    $Tv_{i} = w_{1} + \cdots + w_{m}$ for every positive integer $i\in[\![1,n]\!]$. On the other hand, $w_{1} + \cdots + w_{m}\ne 0$, because $w_{1}, \ldots, w_{m}$ is linearly independent. Moreover, the list $Tv_{1}, \ldots, Tv_{n}$ spans $\range{T}$. So $\dim\range{T} = 1$.

    $(\Leftarrow)$ $\dim\range{T} = 1$.

    Suppose that $\dim V = n, \dim W = m$. Let $v_{1}$ be a vector in $V$ such that $Tv_{1}\ne 0$.

    For each positive integer $k \in [\![ 2, n ]\!]$, there exists a vector $v$ such that $v_{1}, \ldots, v_{k-1}, v$ is linearly independent. If $Tv \ne 0$, we define $v_{k} = a^{-1}v$ (where $Tv = a\cdot Tv_{1}$), otherwise, we define $v_{k} = v + v_{1}$. At the end of this process, we obtain the list $v_{1}, \ldots, v_{n}$ of linearly independent vectors that spans $V$ and $Tv_{i}\ne 0$. Moreover, $Tv_{1} = \cdots = Tv_{n}$.

    Let $w_{1} = Tv_{1}$. Extend $w_{1}$ to $w_{1}, \ldots, w_{m}$ to obtain a basis of $W$. Let $u_{1} = w_{1} - (w_{2} + \cdots + w_{m})$. The list $u_{1}, w_{2}, \ldots, w_{n}$ is linearly independent and has length $m$ so it is a basis of $W$. $Tv_{i} = u_{1} + w_{2} + \cdots + w_{m}$ for every positive integer $i\in[\![1,n]\!]$. So the matrix of $T$ with respect to bases $v_{1}, \ldots, v_{n}$ and $u_{1}, w_{2}, \ldots, w_{m}$ has all entries equal $1$.
\end{proof}
\newpage

% chapter3:sectionC:exercise3
\begin{exercise}
    Suppose $v_{1} , \ldots, v_{n}$ is a basis of $V$ and $w_{1} , \ldots, w_{m}$ is a basis of $W$.
    \begin{enumerate}[label={(\alph*)}]
        \item Show that if $S, T\in \mathcal{L}(V, W)$, then $\mathcal{M}(S + T) = \mathcal{M}(S) + \mathcal{M}(T)$.
        \item Show that if $\lambda\in\mathbb{F}$ and $T\in\mathcal{L}(V, W)$, then $\mathcal{M}(\lambda T) = \lambda \mathcal{M}(T)$.
    \end{enumerate}
\end{exercise}

\begin{proof}
    I skip this exercise.
\end{proof}
\newpage

% chapter3:sectionC:exercise4
\begin{exercise}
    Suppose that $D \in \mathcal{L}(\mathcal{P}_{3} (\mathbb{R}), \mathcal{P}_{2} (\mathbb{R}))$ is the differentiation map defined by $Dp = p'$. Find a basis of $\mathcal{P}_{3} (\mathbb{R})$ and a basis of $\mathcal{P}_{2} (\mathbb{R})$ such that the matrix of $D$ with respect to these bases is
    \[
        \begin{pmatrix}
            1 & 0 & 0 & 0 \\
            0 & 1 & 0 & 0 \\
            0 & 0 & 1 & 0
        \end{pmatrix}.
    \]
\end{exercise}

\begin{proof}
    I choose $\frac{1}{3}X^{3}$, $\frac{1}{2}X^{2}$, $X$, $1$ to be a basis of $\mathcal{P}_{3}(\mathbb{R})$, and $X^{2}$, $X$, $1$ to be a basis of $\mathcal{P}_{3}(\mathbb{R})$. Then the matrix of $D$ with respect to these bases is
    \[
        \begin{pmatrix}
            1 & 0 & 0 & 0 \\
            0 & 1 & 0 & 0 \\
            0 & 0 & 1 & 0
        \end{pmatrix}.\qedhere
    \]
\end{proof}
\newpage

% chapter3:sectionC:exercise5
\begin{exercise}
    Suppose $V$ and $W$ are finite-dimensional and $T \in \mathcal{L}(V, W)$. Prove that there exist a basis of $V$ and a basis of $W$ such that with respect to these bases, all entries of $\mathcal{M}(T)$ are $0$ except that the entries in row $k$, column $k$, equal $1$ if $1\leq k \leq \dim\range{T}$.
\end{exercise}

\begin{proof}
    If $T = 0$, then for any choice of bases, all entries of $\mathcal{M}(T)$ are $0$. Otherwise,

    Let $v_{1}, \ldots, v_{n}$ be a basis of $V$. The list $Tv_{1}, \ldots, Tv_{n}$ spans $\range{T}$, and this list can be reduced to a linearly independent list that spans $\range{T}$. Let $Tu_{1}, \ldots, Tu_{\ell}$ ($\ell\leq n$) be vectors from the list $Tv_{1}, \ldots, Tv_{n}$ such that $Tu_{1}, \ldots, Tu_{\ell}$ are linearly independent and spans $\range{W}$.

    $Tu_{1}, \ldots, Tu_{\ell}$ is linearly independent in $W$, then the list $u_{1}, \ldots, u_{\ell}$ is linearly independent in $V$. Next, I will prove that $V = \kernel{T} \oplus\text{span}(u_{1}, \ldots, u_{\ell})$.

    Let $v$ be a vector in $V$, there exist scalars $a_{1}, \ldots, a_{\ell}$ such that
    \[
        Tv = a_{1}Tu_{1} + \cdots + a_{\ell}Tu_{\ell}.
    \]

    So
    \[
        T(v - a_{1}u_{1} - \cdots - a_{\ell}u_{\ell}) = 0.
    \]

    Therefore $v = (a_{1}u_{1} + \cdots + a_{\ell}u_{\ell}) + u$, where $u\in\kernel{T}$. If $v_{0}$ is a vector in $\kernel{T}\cap \text{span}(u_{1}, \ldots, u_{\ell})$, then there exist scalars $x_{1}, \ldots, x_{\ell}$ such that $v_{0} = x_{1}u_{1} + \cdots + x_{\ell}u_{\ell}$ and $Tv_{0} = 0$. It follows that
    \[
        x_{1}Tu_{1} + \cdots + x_{\ell}Tu_{\ell} = 0
    \]

    and this implies $x_{1} = \cdots = x_{\ell} = 0$ because $Tu_{1}, \ldots, Tu_{\ell}$ is a linearly independent list. So
    \[
        \kernel{T}\cap\text{span}(u_{1}, \ldots, u_{\ell}) = \{0\}.
    \]

    Hence $V = \kernel{T}\oplus\text{span}(u_{1}, \ldots, u_{\ell})$.

    Let $u_{k+1}, \ldots, u_{n}$ be a basis of $\kernel{T}$, then $u_{1}, \ldots, u_{n}$ is a basis of $V$.

    Let $w_{1} = Tu_{1}, \ldots, w_{\ell} = Tu_{\ell}$ and extend this list to create a basis of $W$, and let it be $w_{1}, \ldots, w_{m}$. Then
    \[
        Tu_{k} = \begin{cases}
            w_{k} & \text{if $1\leq k\leq \ell$ where $\ell = \dim\range{T}$}, \\
            0     & \text{otherwise}.
        \end{cases}
    \]

    The matrix of $T$ with respect to bases $u_{1}, \ldots, u_{n}$ of $V$ and $w_{1}, \ldots, w_{m}$ of $W$ satisfies: all of its entries are $0$ except the entries in row $k$, column $k$, equal $1$ when $1\leq k\leq \dim\range{T}$.
\end{proof}
\newpage

% chapter3:sectionC:exercise6
\begin{exercise}
    Suppose $v_{1}, \ldots, v_{m}$ is a basis of $V$ and $W$ is finite-dimensional. Suppose $T \in \mathcal{L}(V, W)$. Prove that there exists a basis $w_{1}, \ldots, w_{n}$ of $W$ such that all entries in the first column of $\mathcal{M}(T)$ [with respect to the bases $v_{1}, \ldots, v_{m}$ and $w_{1}, \ldots, w_{n}$] are $0$ except for possibly a $1$ in the first row, first column.
\end{exercise}

\begin{proof}
    If $T = 0$, then for any choice of basis of $W$, all entries of $\mathcal{M}(T)$ are $0$.

    If $T\ne 0$, then there exists a vector $v$ in the list $v_{1}, \ldots, v_{m}$ such that $Tv\ne 0$. Without loss of generality, suppose that $Tv_{1}\ne 0$. Let $w_{1} = Tv_{1}$. Let $w_{1}, \ldots, w_{n}$ be a basis of $W$, then $Tv_{1} = 1w_{1} + 0w_{2} + \cdots + 0w_{n}$.

    The matrix of $T$ with respect to bases $v_{1}, \ldots, v_{m}$ of $V$ and $w_{1}, \ldots, w_{n}$ of $W$ satisfies: all entries in the first column are $0$, except for a $1$ in the first row, first column.
\end{proof}
\newpage

% chapter3:sectionC:exercise7
\begin{exercise}
    Suppose $w_{1}, \ldots, w_{n}$ is a basis of $W$ and $V$ is finite-dimensional. Suppose $T \in \mathcal{L}(V, W)$. Prove that there exists a basis $v_{1}, \ldots, v_{m}$ of $V$ such that all entries in the first row of $\mathcal{M}(T)$ [with respect to the bases $v_{1}, \ldots, v_{m}$ and $w_{1}, \ldots, w_{n}$] are $0$ except for possibly a $1$ in the first row, first column.
\end{exercise}

\begin{proof}
    Let $u_{1}, \ldots, u_{m}$ be a basis of $V$. I consider the two following cases.

    If the linear combination of $Tu_{i}$ with respect to $w_{1}, \ldots, w_{n}$ has coefficient $0$ with respect to $w_{1}$ for every $i\in[\![1,n]\!]$, then in the matrix of $T$ with respect to bases $u_{1}, \ldots, u_{m}$ and $w_{1}, \ldots, w_{n}$, all entries in the first row are $0$.

    If there exists $k\in[\![1,n]\!]$ such that the coefficient of $w_{1}$ in the linear combination of $Tu_{k}$ with respect to $w_{1}, \ldots, w_{n}$ is nonzero. Let
    \[
        Tu_{k} = b_{1}w_{1} + \cdots + b_{n}w_{n}.
    \]

    I choose $v_{1} = {b^{-1}_{1}}u_{k}$, so $Tv_{1} = w_{1} + b^{-1}_{1}b_{2}w_{2} + \cdots + b^{-1}_{1}b_{n}w_{n}$.

    For each integer $k\in[\![2, m]\!]$, there exist a vector $v$ such that the list $v_{1}, \ldots, v_{k-1}, v$ is linearly independent. If $Tv = a_{1}w_{1} + \cdots + a_{n}w_{n}$, then we let $v_{k} = v - a_{1}v_{1}$. The list $v_{1}, \ldots, v_{k-1}, v_{k}$ is also linearly independent. At the end of this process, we obtain the basis $v_{1}, \ldots, v_{m}$, and in the matrix of $T$ with respect to bases $v_{1}, \ldots, v_{m}$ and $w_{1}, \ldots, w_{n}$, all entries on the first row is $0$, except for the entry in the first row, first column.
\end{proof}
\newpage

% chapter3:sectionC:exercise8
\begin{exercise}
    Suppose $A$ is an $m$-by-$n$ matrix and $B$ is an $n$-by-$p$ matrix. Prove that
    \[
        {(AB)}_{j,\cdot} = A_{j,\cdot}\cdot B
    \]

    for each $1\leq j\leq m$. In other words, show that row $j$ of $AB$ equals row $j$ of $A$ times $B$.
\end{exercise}

\begin{proof}
    I skip this exercise.
\end{proof}
\newpage

% chapter3:sectionC:exercise9
\begin{exercise}
    Suppose $a = \begin{pmatrix}a_{1} & \cdots & a_{n}\end{pmatrix}$ is a $1$-by-$n$ matrix and $B$ is an $n$-by-$p$ matrix. Prove that
    \[
        aB = a_{1}B_{1,\cdot} + \cdots + a_{n}B_{n,\cdot}.
    \]

    In other words, show that $aB$ is a linear combination of the rows of $B$, with the scalars that multiply the rows coming from $a$.
\end{exercise}

\begin{proof}
    I skip this exercise.
\end{proof}
\newpage

% chapter3:sectionC:exercise10
\begin{exercise}
    Give an example of $2$-by-$2$ matrices $A$ and $B$ such that $AB \ne BA$.
\end{exercise}

\begin{proof}
    I skip this exercise.
\end{proof}
\newpage

% chapter3:sectionC:exercise11
\begin{exercise}
    Prove that the distributive property holds for matrix addition and matrix multiplication. In other words, suppose $A$, $B$, $C$, $D$, $E$, and $F$ are matrices whose sizes are such that $A(B + C)$ and $(D + E)F$ make sense. Explain why $AB + AC$ and $DF + EF$ both make sense and prove that
    \[
        A(B + C) = AB + AC \quad\text{ and }\quad (D + E)F = DF + EF.
    \]
\end{exercise}

\begin{proof}
    I skip this exercise.
\end{proof}
\newpage

% chapter3:sectionC:exercise12
\begin{exercise}
    Prove that matrix multiplication is associative. In other words, suppose $A$, $B$,and $C$ are matrices whose sizes are such that $(AB)C$ makes sense. Explain why $A(BC)$ makes sense and prove that
    \[
        (AB)C = A(BC).
    \]
\end{exercise}

\begin{proof}
    I skip this exercise.
\end{proof}
\newpage

% chapter3:sectionC:exercise13
\begin{exercise}
    Suppose $A$ is an $n$-by-$n$ matrix and $1\leq j, k\leq n$. Show that the entry in row $j$, column $k$, of $A^{3}$ (which is defined to mean $AAA$) is
    \[
        \sum^{n}_{p=1}\sum^{n}_{r=1}A_{j,p}A_{p,r}A_{r,k}
    \]
\end{exercise}

\begin{proof}
    Let $B = A^{2}$. The entry in row $j$, column $k$ of $A^{3}$ is
    \[
        \sum^{n}_{p=1}A_{j,p}B_{p,k}.
    \]

    The entry in row $p$, column $k$ of $B = A^{2}$ is
    \[
        \sum^{n}_{r=1}A_{p,r}A_{r,k}.
    \]

    So the entry in row $j$, column $k$ of $A^{3}$ is
    \[
        \sum^{n}_{p=1}A_{j,p}B_{p,k} = \sum^{n}_{p=1}A_{j,p}\sum^{n}_{r=1}A_{p,r}A_{r,k} = \sum^{n}_{p=1}\sum^{n}_{r=1}A_{j,p}A_{p,r}A_{r,k}.\qedhere
    \]
\end{proof}
\newpage

% chapter3:sectionC:exercise14
\begin{exercise}
    Suppose $m$ and $n$ are positve integers. Prove that the function $A\mapsto A^{t}$ is a linear map from $\mathbb{F}^{m,n}$ to $\mathbb{F}^{n,m}$.
\end{exercise}

\begin{proof}
    I skip this exercise.
\end{proof}
\newpage

% chapter3:sectionC:exercise15
\begin{exercise}
    Prove that if $A$ is an $m$-by-$n$ matrix and $C$ is an $n$-by-$p$ matrix, then
    \[
        {(AC)}^{t} = C^{t}A^{t}.
    \]
\end{exercise}

\begin{proof}
    $AC$ is a $m$-by-$p$ matrix, so ${(AC)}^{t}$ is a $p$-by-$m$ matrix. $C^{t}$ is a $p$-by-$n$ matrix, $A^{t}$ is a $n$-by-$m$ matrix, so $C^{t}A^{t}$ is a $p$-by-$m$ matrix.

    The entry in row $j$, column $k$ of ${(AC)}^{t}$ is also the entry in row $k$, column $j$ of $AC$, which equals row $k$ of $A$ times column $k$ of $C$.

    The entry in row $j$, column $k$ of $C^{t}A^{t}$ equals row $j$ of $C^{t}$ times column $k$ of $A^{t}$, equals row $k$ of $A$ times column $j$ of $C$.

    Thus ${(AC)}^{t} = C^{t}A^{t}$.
\end{proof}
\newpage

% chapter3:sectionC:exercise16
\begin{exercise}
    Suppose $A$ is an $m$-by-$n$ matrix with $A\ne 0$. Prove that the rank of $A$ is $1$ if and only if there exist $(c_{1}, \ldots, c_{m})\in\mathbb{F}^{m}$ and $(d_{1}, \ldots, d_{n})\in\mathbb{F}^{n}$ such that $A_{j,k} = c_{j}d_{k}$ for every $j = 1, \ldots, m$ and every $k = 1, \ldots, n$.
\end{exercise}

\begin{proof}
    $(\Rightarrow)$ There exist $(c_{1}, \ldots, c_{m})\in\mathbb{F}^{m}$ and $(d_{1}, \ldots, d_{n})\in\mathbb{F}^{n}$ such that $A_{j,k} = c_{j}d_{k}$ for every $j = 1, \ldots, m$ and every $k = 1, \ldots, n$.

    Let $v = \begin{pmatrix}d_{1} & \cdots & d_{n}\end{pmatrix}$ be a row matrix in $\mathbb{F}^{1,n}$. Then row $j$ of $A$, which is $A_{j,\cdot}$, equals $c_{j} v$, for every $j = 1, \ldots, m$. Because $A\ne 0$, then $v\ne 0$ and there exists a $c_{j}\ne 0$. So every other row is a multiple of the row $j$ of $A$. Therefore $\rank{A} = 1$.

    $(\Leftarrow)$ $\rank{A} = 1$.

    Let $v = (d_{1}, \ldots, d_{n})$ be a basis of the span of rows of $A$ in $\mathbb{F}^{1,n}$. Then for every $j = 1, \ldots, m$, there exists a scalar $c_{j}$ such that $A_{j,\cdot} = c_{j}v$. Hence there exist $(c_{1}, \ldots, c_{m})\in\mathbb{F}^{m}$ and $(d_{1}, \ldots, d_{n})\in\mathbb{F}^{n}$ such that $A_{j,k} = c_{j}d_{k}$ for every $j = 1, \ldots, m$ and every $k = 1, \ldots, n$.
\end{proof}
\newpage

% chapter3:sectionC:exercise17
\begin{exercise}
    Suppose $T\in \mathcal{L}(V)$, and $u_{1}, \ldots, u_{n}$ and $v_{1}, \ldots, v_{n}$ are bases of $V$. Prove that the following are equivalent.
    \begin{enumerate}[label={(\alph*)}]
        \item $T$ is injective.
        \item The columns of $\mathcal{M}(T)$ are linearly independent in $\mathbb{F}^{n,1}$.
        \item The columns of $\mathcal{M}(T)$ span $\mathbb{F}^{n,1}$.
        \item The rows of $\mathcal{M}(T)$ span $\mathbb{F}^{1,n}$.
        \item The rows of $\mathcal{M}(T)$ are linearly independent in $\mathbb{F}^{1,n}$.
    \end{enumerate}

    Here $\mathcal{M}(T)$ means $\mathcal{M}(T, (u_{1}, \ldots, u_{n}), (v_{1}, \ldots, v_{n}))$.
\end{exercise}

\begin{proof}
    Let $A = \mathcal{M}(T, (u_{1}, \ldots, u_{n}), (v_{1}, \ldots, v_{n}))$.

    $(a) \Rightarrow (b)$ $T$ is injective, then $\sum^{n}_{i=1}a_{i}Tu_{i} = T(\sum^{n}_{i=1}a_{i}u_{i})$ is $0$ if and only if $\sum^{n}_{i=1}a_{i}u_{i} = 0$ (because when $T$ is injective, $\kernel{T} = \{0\}$). $\sum^{n}_{i=1}a_{i}u_{i} = 0$ if and only if $a_{1} = \cdots = a_{n} = 0$, because $u_{1}, \ldots, u_{n}$ is a basis of $V$. So $Tu_{1}, \ldots, Tu_{n}$ is linearly independent.

    Assume that $x_{1}A_{\cdot,1} + \cdots + x_{n}A_{\cdot,n} = 0$. Then $\sum^{n}_{j=1}A_{i,j}x_{j} = 0$ for every positive integer $i = 1, \ldots, n$, and
    \begin{align*}
        \sum^{n}_{i=1}x_{i}Tu_{i} & = \sum^{n}_{i=1}x_{i}\left(\sum^{n}_{j=1}A_{j,i}v_{j}\right)  \\
                                  & = \sum^{n}_{i=1} \left(\sum^{n}_{i=1}A_{j,i}x_{i}\right)v_{i} \\
                                  & = \sum^{n}_{i=1} 0v_{i} = 0.
    \end{align*}

    So $x_{1} = \cdots = x_{n} = 0$, because $Tu_{1}, \ldots, Tu_{n}$ is linearly independent. Therefore the columns of $\mathcal{M}(T)$ are linearly independent in $\mathbb{F}^{n,1}$.

    $(a) \Leftarrow (b)$ The columns of $\mathcal{M}(T)$ are linearly independent in $\mathbb{F}^{n,1}$.

    Assume that $x_{1}Tu_{1} + \cdots + x_{n}Tu_{n} = 0$. Then
    \begin{align*}
        0 = \sum^{n}_{i=1}x_{i}Tu_{i} & = \sum^{n}_{i=1}x_{i}\left(\sum^{n}_{j=1}A_{j,i}v_{j}\right)   \\
                                      & = \sum^{n}_{i=1} \left(\sum^{n}_{i=1}A_{j,i}x_{i}\right)v_{i}.
    \end{align*}

    Since $v_{1}, \ldots, v_{n}$ is a basis of $V$, then $\sum^{n}_{i=1}A_{j,i}x_{i} = 0$ for every $j = 1, \ldots, n$, equivalently, $\sum^{n}_{i=1}x_{i}A_{\cdot,i} = 0$. Besides, the columns of $\mathcal{M}(T)$ are linearly independent, so $x_{1} = \cdots = x_{n} = 0$. Therefore $Tu_{1}, \ldots, Tu_{n}$ is linear independent and is a basis of $V$. Let $u$ be a vector in $\kernel{T}$, then $u = \sum^{n}_{i=1}a_{i}u_{i}$. So $0 = Tu = \sum^{n}_{i=1}a_{i}Tu_{i}$, it follows that $a_{1} = \cdots = a_{n} = 0$, which means $u = 0$. Hence $\kernel{T} = \{0\}$, and we conclude that $T$ is injective.

    $(b) \Leftrightarrow (c)$ If the columns of $\mathcal{M}(T)$ are linearly independent in $\mathbb{F}^{n,1}$ then they form a basis of $\mathbb{F}^{n,1}$, since there are $n$ of them and they are linearly independent. So they also span $\mathbb{F}^{n,1}$.

    If the columns of $\mathcal{M}(T)$ span $\mathbb{F}^{n,1}$, then the dimension of the span of them is $n$, which equals to the number of columns. So they are also a basis of $\mathbb{F}^{n,1}$, which is linearly independent.

    $(c) \Leftrightarrow (d)$ The columns of $\mathcal{M}(T)$ span $\mathbb{F}^{n,1}$ if and only if the dimension of the span of the columns is $n$. The rows of $\mathcal{M}(T)$ span $\mathbb{F}^{1,n}$ if and only if the dimension of the span of the rows is $n$. On the other hand, the row rank and column rank of $\mathcal{M}(T)$ are identical, then the result follows.

    $(d) \Leftrightarrow (e)$ If the rows of $\mathcal{M}(T)$ span $\mathbb{F}^{1,n}$, then the dimension of the span of them is $n$, which equals to the number of rows. So they are also a basis of $\mathbb{F}^{1,n}$, which is linearly independent.

    If the rows of $\mathcal{M}(T)$ are linearly independent in $\mathbb{F}^{1,n}$ then they form a basis of $\mathbb{F}^{n,1}$, since there are $n$ of them and they are linearly independent. So they also span $\mathbb{F}^{1,n}$.
\end{proof}
\newpage

\section{Invertibility and Isomorphisms}

% chapter3:sectionD:exercise1
\begin{exercise}\label{chapter3:sectionD:exercise1}
    Suppose $T \in \mathcal{L}(V, W)$ is invertible. Show that $T^{-1}$ is invertible and
    \[
        {\left(T^{-1}\right)}^{-1} = T.
    \]
\end{exercise}

\begin{proof}
    Since $T^{-1}$ is the inverse of $T$, then $T^{-1}T = \text{id}_{V}$ and $TT^{-1} = \text{id}_{W}$. Due to the definition of inverse linear map, $T$ is the inverse of $T^{-1}$. Therefore ${\left(T^{-1}\right)}^{-1} = T$.
\end{proof}
\newpage

% chapter3:sectionD:exercise2
\begin{exercise}
    Suppose $T\in \mathcal{L}(U, V)$ and $S \in \mathcal{L}(V, W)$ are both invertible linear maps. Prove that $ST\in \mathcal{L}(U, W)$ is invertible and that ${(ST)}^{-1} = T^{-1}S^{-1}$.
\end{exercise}

\begin{proof}
    \[
        \begin{split}
            {(ST)}{(T^{-1}S^{-1})} = S(TT^{-1})S^{-1} = S\text{id}_{V}S^{-1} = SS^{-1} = \text{id}_{W}, \\
            {(T^{-1}S^{-1})(ST)} = T^{-1}(S^{-1}S)T = T^{-1}\text{id}_{V}T = T^{-1}T = \text{id}_{U}
        \end{split}
    \]

    So $ST$ is invertible and ${(ST)}^{-1} = T^{-1}S^{-1}$.
\end{proof}
\newpage

% chapter3:sectionD:exercise3
\begin{exercise}\label{chapter3:sectionD:exercise3}
    Suppose $V$ is finite-dimensional and $T \in \mathcal{L}(V)$. Prove that the following are equivalent
    \begin{enumerate}[label={(\alph*)}]
        \item $T$ is invertible.
        \item $Tv_{1}, \ldots, Tv_{n}$ is a basis of $V$ for every basis $v_{1}, \ldots, v_{n}$ of $V$.
        \item $Tv_{1}, \ldots, Tv_{n}$ is a basis of $V$ for some basis $v_{1}, \ldots, v_{n}$ of $V$.
    \end{enumerate}
\end{exercise}

\begin{proof}
    $(a) \Rightarrow (b)$ Let $v_{1}, \ldots, v_{n}$ be a basis of $V$. Suppose that
    \[
        0 = x_{1}Tv_{1} + \cdots + x_{n}T_{n}.
    \]

    Then $T(x_{1}v_{1} + \cdots + x_{n}v_{n}) = 0$. Because $T$ is invertible,
    \[
        x_{1}v_{1} + \cdots + x_{n}v_{n} = T^{-1}T(x_{1}v_{1} + \cdots + x_{n}v_{n}) = 0.
    \]

    It follows that $x_{1} = \cdots = x_{n} = 0$. So $Tv_{1}, \ldots, Tv_{n}$ is linearly independent. This list has length $n$ so it is a basis of $V$.

    $(b) \Rightarrow (c)$ This is obvious.

    $(c) \Rightarrow (a)$ $Tv_{1}, \ldots, Tv_{n}$ is a basis of $V$ for a basis $v_{1}, \ldots, v_{n}$ of $V$.

    Let $v$ be a vector in $\kernel{T}$, and $v = x_{1}v_{1} + \cdots + x_{n}v_{n}$ (there exist such scalar because $v_{1}, \ldots, v_{n}$ is a basis of $V$).
    \[
        0 = Tv = T(x_{1}v_{1} + \cdots + x_{n}v_{n}) = x_{1}Tv_{1} + \cdots + x_{n}Tv_{n}.
    \]

    Since $Tv_{1}, \ldots, Tv_{n}$ is linearly independent, we get $x_{1} = \cdots = x_{n}$. So $v = 0$, which means $\kernel{T} = \{0\}$ and $T$ is injective. On the other hand, $Tv_{1}, \ldots, Tv_{n}$ spans $V$, the codomain of $T$, so $T$ is surjective. $T$ is a linear map whose domain and codomain are finite-dimensional and have the same dimension, so $T$ is invertible.
\end{proof}
\newpage

% chapter3:sectionD:exercise4
\begin{exercise}
    Suppose $V$ is finite-dimensional and $\dim V > 1$. Prove that the set of noninvertible linear maps from $V$ to itself is not a subspace of $\mathcal{L}(V)$.
\end{exercise}

\begin{proof}
    Let $v_{1}, v_{2}, \ldots, v_{n}$ be a basis of $V$.

    Let $S_{i}$ be the linear map that
    \[
        S_{i}v_{j} = \begin{cases}
            v_{i} & \text{if $i = j$}, \\
            0     & \text{otherwise}.
        \end{cases}
    \]

    Then $S_{1}, \ldots, S_{n}$ are noninvertible. But $\sum^{n}_{k=1}S_{k} = \text{id}_{V}$, which is invertible. So the set of noninvertible linear maps from $V$ to itself is not a subspace of $\mathcal{L}(V)$, because it is not closed under linear maps addition.
\end{proof}
\newpage

% chapter3:sectionD:exercise5
\begin{exercise}
    Suppose $V$ is finite-dimensional, $U$ is a subspace of $V$, and $S \in \mathcal{L}(U, V)$. Prove that there exists an invertible linear map $T$ from $V$ to itself such that $Tu = Su$ for every $u\in U$ if and only if $S$ is injective.
\end{exercise}

\begin{proof}
    Let $u_{1}, \ldots, u_{k}$ be a basis of $U$. Extend this list to a basis of $V$ and let it be $u_{1}, \ldots, u_{k}, u_{k+1}, \ldots, u_{n}$.

    $(\Rightarrow)$ There exists an invertible linear map $T$ from $V$ to itself such that $Tu = Su$ for every $u\in U$.

    Let $v$ be a vector in $\kernel{S}$, then $Tv = Sv = 0$. Because $T$ is invertible, then $T$ is also injective, so $Tv = 0$ implies $v = 0$. Therefore $\kernel{S} = \{0\}$. Hence $S$ is injective.

    $(\Leftarrow)$ $S$ is injective.

    Because $S$ is injective, the list $Su_{1}, \ldots, Su_{k}$ is linearly independent. Extend this list to create a basis of $V$ and let it be $Su_{1}, \ldots, Su_{k}, v_{k+1}, \ldots, v_{n}$. I define the linear map $T$ as follows:
    \[
        Tu_{i} = \begin{cases}
            Su_{i} & \text{if $1\leq i\leq k$} \\
            v_{i}  & \text{otherwise}.
        \end{cases}
    \]

    Apply Exercise~\ref{chapter3:sectionD:exercise3} to $T$ and bases $u_{1}, \ldots, u_{n}$ and $Su_{1}, \ldots, Su_{k}, v_{k+1}, \ldots, v_{n}$, we conclude that $T$ is invertible.

    Let $u$ be a vector in $U$, and $u = x_{1}u_{1} + \cdots + x_{k}u_{k}$. According to the definition of $T$
    \[
        Tu = T\left(\sum^{k}_{j=1}x_{j}u_{j}\right) = \sum^{k}_{j=1}x_{j}Tu_{j} = \sum^{k}_{j=1}Su_{j} = S\left(\sum^{k}_{j=1}x_{j}u_{j}\right) = Su.\qedhere
    \]

    for every $u\in U$.
\end{proof}
\newpage

% chapter3:sectionD:exercise6
\begin{exercise}
    Suppose that $W$ is finite-dimensional and $S, T \in \mathcal{L}(V, W)$. Prove that $\kernel{S} = \kernel{T}$ if and only if there exists an invertible $E \in \mathcal{L}(W)$ such that $S = ET$.
\end{exercise}

\begin{proof}
    $W$ is finite-dimensional, then so are $\range{S}$ and $\range{T}$.

    $(\Rightarrow)$ There exists an invertible $E \in \mathcal{L}(W)$ such that $S = ET$.

    If vector $v\in\kernel{T}$, then $Sv = (ET)(v) = E(Tv) = 0$, so $v\in\kernel{S}$. If vector $v\in\kernel{S}$, then $Tv = (E^{-1}S)v = E^{-1}(Sv) = 0$, so $v\in\kernel{T}$. Therefore $\kernel{S} = \kernel{T}$.

    $(\Leftarrow)$ $\kernel{S} = \kernel{T}$. Let $U = \kernel{S}$, of course $U = \kernel{T}$.

    Let $Sv_{1}, \ldots, Sv_{n}$ be a basis of $\range{S}$, then $v_{1}, \ldots, v_{n}$ is linearly independent in $V$. Let $v$ be a vector in $V$. There exist scalars $x_{k}$ for $k = 1,\ldots, n$ such that $Sv = x_{1}Sv_{1} + \cdots + x_{n}Sv_{n}$. So
    \[
        S(v - x_{1}v_{1} - \cdots - x_{n}v_{n}) = 0.
    \]

    Therefore $v - x_{1}v_{1} - \cdots - x_{n}v_{n}$ is in $U$ and $V = U + \text{span}(v_{1}, \ldots, v_{n})$.

    Let $u$ be a vector in $U\cap \text{span}(v_{1}, \ldots, v_{n})$. Then $Su = 0$ and there exist scalars $a_{k}$ for $k = 1,\ldots, n$ such that
    \[
        u = a_{1}v_{1} + \cdots + a_{n}v_{n}.
    \]

    $0 = Su = a_{1}Sv_{1} + \cdots + a_{n}Sv_{n}$. Since $Sv_{1}, \ldots, Sv_{n}$ is linearly independent, it follows that $a_{1} = \cdots = a_{n} = 0$. So $U\cap \text{span}(v_{1}, \ldots, v_{n}) = \{ 0 \}$. Therefore $V = U \oplus \text{span}(v_{1}, \ldots, v_{n})$.

    Let $v$ be a vector in $V$, then $v = u + c_{1}v_{1} + \cdots + c_{n}v_{n}$.
    \[
        Tv = Tu + c_{1}Tv_{1} + \cdots + c_{n}Tv_{n} = c_{1}Tv_{1} + \cdots + c_{n}Tv_{n}.
    \]

    Therefore $Tv_{1}, \ldots, Tv_{n}$ spans $\range{T}$.

    Let $d_{1}Tv_{1} + \cdots + d_{n}Tv_{n} = 0$ be a linear combination of $0$ in $\range{T}$, then $T(d_{1}v_{1} + \cdots + d_{n}v_{n}) = 0$. So $d_{1}v_{1} + \cdots + d_{n}v_{n}$ is in $\kernel{T} = U$. However, $\kernel{T}\cap\text{span}(v_{1}, \ldots, v_{n}) = \{0\}$, so $d_{1}v_{1} + \cdots + d_{n}v_{n} = 0$, and $d_{1}v_{1} + \cdots + d_{n}v_{n} = 0$ implies $d_{1} = \cdots = d_{n} = 0$ because $v_{1}, \ldots, v_{n}$ is linearly independent. So $Tv_{1}, \ldots, Tv_{n}$ is linearly independent.

    Hence $Tv_{1}, \ldots, Tv_{n}$ is a basis of $\range{T}$.

    Extend $Sv_{1}, \ldots, Sv_{n}$ to create a basis of $W$ and let it be $Sv_{1}, \ldots, Sv_{n}, w_{n+1}, \ldots, w_{n+m}$.

    Extend $Tv_{1}, \ldots, Tv_{n}$ to create a basis of $W$ and let it be $Tv_{1}, \ldots, Tv_{n}, z_{n+1}, \ldots, z_{n+m}$.

    I define the linear map $E$ in $\lmap{W}$ as follows:
    \[
        E(Tv_{k}) = Sv_{k}\quad \text{(if $1\leq k\leq n$)} \qquad\text{and}\qquad Ez_{k} = w_{k} \quad\text{(if $n+1\leq k\leq n+m$)}.
    \]

    Let $v$ be a vector in $V$, and $v = u + x_{1}v_{1} + \cdots + x_{n}v_{n}$, where $u\in U$.
    \begin{align*}
        (ET)(v) & = E(Tu + x_{1}Tv_{1} + \cdots + x_{n}Tv_{n})               \\
                & = E(x_{1}Tv_{1} + \cdots + x_{n}Tv_{n})                    \\
                & = \sum^{n}_{k=1}x_{k}E(Tv_{k}) = \sum^{n}_{k=1}x_{k}Sv_{k} \\
                & = Su + \sum^{n}_{k=1}x_{k}Sv_{k}                           \\
                & = S(u + x_{1}v_{1} + \cdots + x_{n}v_{n})                  \\
                & = Sv.
    \end{align*}

    I define the linear map $F$ in $\lmap{W}$ as follows:
    \[
        F(Sv_{k}) = Tv_{k}\quad \text{(if $1\leq k\leq n$)} \qquad\text{and}\qquad Fw_{k} = z_{k} \quad\text{(if $n+1\leq k\leq n+m$)}.
    \]

    Then $EF = FE = \text{id}_{W}$, due to the definition of these two linear maps. Therefore $E$ is invertible and $S = ET$.
\end{proof}
\newpage

% chapter3:sectionD:exercise7
\begin{exercise}
    Suppose that $V$ is finite-dimensional and $S, T \in \mathcal{L}(V, W)$. Prove that $\range{S} = \range{T}$ if and only if there exists an invertible $E \in \mathcal{L}(V)$ such that $S = TE$.
\end{exercise}

\begin{proof}
    Since $V$ is finite-dimensional, then so are $\range{S}$ and $\range{T}$.

    $(\Rightarrow)$ There exists an invertible $E \in \mathcal{L}(V)$ such that $S = TE$.

    Then $T = SE^{-1}$.

    If $w$ is a vector in $\range{S}$, then there exists a vector $v$ in $V$ such that $Sv = w$. So $(TE)(v) = w$, which means $T(Ev) = w$, and $w$ is also in $\range{T}$.

    If $w$ is a vector in $\range{T}$, then there exists a vector $v$ in $V$ such that $Tv = w$. So $(SE^{-1})(v) = w$, which means $S(E^{-1}v) = w$, and $w$ is also in $\range{S}$.

    Hence $\range{S} = \range{T}$.

    $(\Leftarrow)$ $\range{S} = \range{T}$. Let $Z = \range{S}$, and of course $Z = \range{T}$.

    Let $w_{1}, \ldots, w_{m}$ be a basis of $Z$. Let $Su_{k} = w_{k}$ and $Tv_{k} = w_{k}$ for $k = 1, \ldots, m$. Then $u_{1}, \ldots, u_{m}$ is linearly independent and $v_{1}, \ldots, v_{m}$ is linearly independent.

    Let $v$ be a vector in $V$, then $Tv = x_{1}Tv_{1} + \cdots + x_{m}Tv_{m}$. From this we get
    \[
        T(v - x_{1}v_{1} - \cdots - x_{m}v_{m}) = 0.
    \]

    This means $v - x_{1}v_{1} - \cdots - x_{m}v_{m}\in \kernel{T}$, so $V = \kernel{T} + \text{span}(v_{1}, \ldots, v_{m})$. Let $v_{0}\in \kernel{T} \cap \text{span}(v_{1}, \ldots, v_{m})$ and $v_{0} = a_{1}v_{1} + \cdots + a_{m}v_{m}$ then
    \[
        0 = Tv_{0} = T(a_{1}v_{1} + \cdots + a_{m}v_{m}) = a_{1}Tv_{1} + \cdots + a_{m}Tv_{m} = a_{1}w_{1} + \cdots + a_{m}w_{m}.
    \]

    Because $w_{1}, \ldots, w_{m}$ is linearly independent, it follows that $a_{1} = \cdots = a_{m} = 0$, and $v_{0} = 0$. Therefore $\kernel{T} + \text{span}(v_{1}, \ldots, v_{m}) = \{0\}$ and $V = \kernel{T} \oplus \text{span}(v_{1}, \ldots, v_{m})$. Let $v_{m+1}, \ldots, v_{m+n}$ be a basis of $\kernel{T}$.

    Similarly, $V = \kernel{S} \oplus\text{span}(u_{1}, \ldots, u_{m})$. Let $u_{m+1}, \ldots, u_{m+n}$ be a basis of $\kernel{T}$.

    I define the linear map $E,F\in\lmap{V}$ as follows: $Eu_{k} = v_{k}$, $Fv_{k} = u_{k}$ for $k = 1,\ldots, m+n$. By this definition, $EF = FE = \text{id}_{V}$.

    If $1\leq k\leq m$, $(TE)(u_{k}) = T(Eu_{k}) = Tv_{k} = w_{k} = Su_{k}$.

    If $m+1\leq k\leq m+n$, $(TE)(u_{k}) = T(Eu_{k}) = Tv_{k} = 0 = Su_{k}$.

    Hence $E$ is an invertible linear map in $\lmap{V}$ and $S = TE$.
\end{proof}
\newpage

% chapter3:sectionD:exercise8
\begin{exercise}
    Suppose $V$ and $W$ are finite-dimensional and $S, T \in \mathcal{L}(V, W)$. Prove that there exist invertible $E_{1} \in \mathcal{L}(V)$ and $E_{2} \in \mathcal{L}(W)$ such that $S = E_{2} TE_{1}$ if and only if $\dim \kernel{S} = \dim \kernel{T}$.
\end{exercise}

\begin{proof}
    $(\Rightarrow)$ There exist invertible $E_{1} \in \mathcal{L}(V)$ and $E_{2} \in \mathcal{L}(W)$ such that $S = E_{2} TE_{1}$.

    Let $v_{S}$ be a vector in $\kernel{S}$, $v_{T}$ be a vector in $\kernel{T}$.
    \[
        \begin{split}
            Sv_{S} = 0 \Leftrightarrow (E_{2}TE_{1})(v_{S}) = 0 \Leftrightarrow (TE_{1})(v_{S}) = 0 \Leftrightarrow T(E_{1}v_{S}) = 0, \\
            Tv_{T} = 0 \Leftrightarrow (E^{-1}_{2}SE^{-1}_{1})(v_{T}) = 0 \Leftrightarrow (SE^{-1}_{1})(v_{T}) = 0 \Leftrightarrow S(E^{-1}_{1}v_{T}) = 0,
        \end{split}
    \]

    so $E_{1}v_{S}\in \kernel{T}$, and $E^{-1}v_{T}\in \kernel{S}$. I define the linear maps $F_{S}\in\lmap{\kernel{S},\kernel{T}}$ and $F_{T}\in\lmap{\kernel{T},\kernel{S}}$ as follows:
    \[
        F_{S}: v\mapsto E_{1}v\qquad  F_{T}: v\mapsto E^{-1}_{1}v
    \]

    Then $F_{S}F_{T} = \text{id}_{\kernel{T}}$ and $F_{T}F_{S} = \text{id}_{\kernel{S}}$. So $F_{S}$ and $F_{T}$ are isomorphisms. Therefore $\kernel{S}$ and $\kernel{T}$ are isomorphic, and $\dim\kernel{S} = \dim\kernel{T}$.

    $(\Leftarrow)$ $\dim\kernel{S} = \dim\kernel{T}$.

    According to the fundamental theorem of linear maps, $\dim\range{S} = \dim V - \dim\kernel{S}$ and $\dim\range{T} = \dim V - \dim\kernel{T}$.

    It follows that $\kernel{S}$ and $\kernel{T}$ are isomorphic, $\range{S}$ and $\range{T}$ are isomorphic.

    Let $Su_{1}, \ldots, Su_{m}$ be a basis of $\range{S}$; $Tv_{1}, \ldots, Tv_{m}$ be a basis of $\range{T}$. Remind that
    \[
        V = \kernel{S}\oplus\text{span}(u_{1}, \ldots, u_{m}) = \kernel{T}\oplus\text{span}(v_{1}, \ldots, v_{m}).
    \]

    Let $u_{m+1}, \ldots, u_{m+n}$ be a basis of $\kernel{S}$, and $v_{m+1}, \ldots, v_{m+n}$ be a basis of $\kernel{T}$. Then $u_{1}, \ldots, u_{m+n}$ and $v_{1}, \ldots, v_{m+n}$ are bases of $V$.

    Extend $Su_{1}, \ldots, Su_{m}$ to create a basis of $W$ and let it be $Su_{1}, \ldots, Su_{m}, u'_{m+1}, \ldots, u'_{m+p}$. Extend $Tv_{1}, \ldots, Tv_{m}$ to create a basis of $W$ and let it be $Tv_{1}, \ldots, Tv_{m}, v'_{m+1}, \ldots, v'_{m+p}$.

    I define $E_{1}\in\lmap{V}$ and $E_{2}\in\lmap{W}$ as follows:
    \begin{itemize}
        \item $E_{1}u_{k} = v_{k}$ for $k = 1, \ldots, m+n$
        \item $E_{2}(Tv_{k}) = Su_{k}$ for $k = 1,\ldots, m$, and $E_{2}v'_{k} = u'_{k}$ for $k = m+1, \ldots, m+p$.
    \end{itemize}

    Then $E_{1}$ and $E_{2}$ are invertible and $S = E_{2}TE_{1}$.
\end{proof}
\newpage

% chapter3:sectionD:exercise9
\begin{exercise}
    Suppose $V$ is finite-dimensional and $T: V \to W$ is a surjective linear map of $V$ onto $W$. Prove that there is a subspace $U$ of $V$ such that $T\vert_{U}$ is an isomorphism of $U$ onto $W$.
\end{exercise}

\begin{proof}
    Since $V$ is finite-dimensional, $\range{T}$ is also finite-dimensional, due to the fundamental theorem of linear maps. Because $T$ is a surjective linear map, it follows that $\range{T} = W$.

    Let $Tu_{1}, \ldots, Tu_{n}$ be a basis of $\range{T} = W$, then $u_{1}, \ldots, u_{n}$ is linearly independent in $V$.

    Let $U = \text{span}(u_{1}, \ldots, u_{n})$, and $u\in U$. Let $w$ be a vector in $W$, then there exist scalars $a_{1}, \ldots, a_{n}$ such that
    \[
        a_{1}Tu_{1} + \cdots + a_{n}Tu_{n} = w.
    \]

    So $T(a_{1}u_{1} + \cdots + a_{n}u_{n}) = w$. Therefore $T\vert_{U}$ is a linear map from $U$ onto $W$. On the other hand, $\dim U = \dim W = n$, so $T\vert_{U}$ is also an isomorphism of $U$ onto $W$.
\end{proof}
\newpage

% chapter3:sectionD:exercise10
\begin{exercise}
    Suppose $V$ and $W$ are finite-dimensional and $U$ is a subspace of $V$. Let
    \[
        \mathcal{E} = \{ T\in\mathcal{L}(V, W): U\subseteq \kernel{T} \}.
    \]

    \begin{enumerate}[label={(\alph*)}]
        \item Show that $\mathcal{E}$ is a subspace of $\mathcal{L}(V, W)$.
        \item Find a formula for $\dim\mathcal{E}$ in terms of $\dim V$, $\dim W$, $\dim U$.
    \end{enumerate}
\end{exercise}

\begin{proof}
    $0\in \lmap{V, W}$ is in $\mathcal{E}$, because $\kernel{0} = V$ and $U$ is a subspace of $V$.

    If $S, T$ are in $\mathcal{E}$, then $S + T$ is also in $\mathcal{E}$, because for every $u\in U$
    \[
        (S + T)(u) = Su + Tu = 0 + 0 = 0.
    \]

    $\lambda S$ is also in $\mathcal{E}$ for every $\lambda\in\mathbb{F}$ because for every $u\in U$
    \[
        (\lambda S)(u) = \lambda Su = \lambda 0 = 0.
    \]

    So $\mathcal{E}$ is a subspace of $\lmap{V, W}$.

    \bigskip

    Let $u_{1}, \ldots, u_{m}$ be a basis of $U$, extend this list to create a basis of $V$ and let it be $u_{1}, \ldots, u_{m}, v_{1}, \ldots, v_{n}$. Let $V_{1} = \text{span}(v_{1}, \ldots, v_{n})$.

    I define a map $f$ from $\mathcal{E}$ to $\lmap{V_{1}, W}$ as follows: $f: T\mapsto T\vert_{V_{1}}$. $f$ is a linear map.

    Let $S$ be a linear map in $\kernel{f}$, then $S\vert_{V_{1}}v_{k} = 0$ for $k = 1, \ldots, n$, so $S = 0$. Therefore $\kernel{f} = 0$ and $f$ is injective.

    On the other hand, for every $R$ in $\lmap{V_{1}, W}$, there exists a linear map $Z$ such that $Zu_{1} = \cdots = Zu_{m} = 0$ and $Zv_{k} = Rv_{k}$ for $k = 1, \ldots, n$. So $f$ is surjective.

    Therefore $f$ is an isomorphism from $\mathcal{E}$ to $\lmap{V_{1}, W}$. Hence
    \[
        \dim\mathcal{E} = (\dim V_{1})(\dim W) = (\dim V - \dim U)(\dim W).
    \]
\end{proof}
\newpage

% chapter3:sectionD:exercise11
\begin{exercise}\label{chapter3:sectionD:exercise11}
    Suppose $V$ is finite-dimensional and $S, T \in \mathcal{L}(V)$. Prove that
    \[
        \text{$ST$ is invertible} \Longleftrightarrow \text{$S$ and $T$ are invertible.}
    \]
\end{exercise}

\begin{proof}
    If $S, T$ are invertible, then $ST$ is invertible.

    If $ST$ is invertible, then $ST$ is injective and surjective. For each vector $w$ in $W$, there exists vector $v$ in $V$ such that $(ST)(v) = w$. $S(Tv) = w$ implies that $S$ is surjective. If $v_{1}, v_{2}$ are two different vectors in $V$, then $(ST)(v_{1})\ne (ST)(v_{2})$, and $Tv_{1}\ne Tv_{2}$, so $T$ is injective. Because $S, T\in\lmap{V}$ and $V$ is finite-dimensional, and $S$ is surjective, $T$ is injective, it follows that $S$ and $T$ are invertible.
\end{proof}
\newpage

% chapter3:sectionD:exercise12
\begin{exercise}\label{chapter3:sectionD:exercise12}
    Suppose $V$ is finite-dimensional and $S, T, U \in \mathcal{L}(V)$ and $STU = I$. Show that $T$ is invertible and that $T^{-1} = US$.
\end{exercise}

\begin{proof}
    $I = (S)(TU) = (ST)(U)$. According to Exercise~\ref{chapter3:sectionD:exercise11}, $S$ and $U$ are invertible.
    \[
        T = ITI = (S^{-1}S)T(UU^{-1}) = S^{-1}(STU)U^{-1} = S^{-1}IU^{-1} = S^{-1}U^{-1}.
    \]

    According Exercise~\ref{chapter3:sectionD:exercise1}, $T^{-1} = US$.
\end{proof}
\newpage

% chapter3:sectionD:exercise13
\begin{exercise}
    Show that the result in Exercise~\ref{chapter3:sectionD:exercise12} can fail without the hypothesis that $V$ is finite-dimensional.
\end{exercise}

\begin{proof}
    Let $V$ be the space of sequences of real numbers.

    Let $T$ be the identity map in $\lmap{V}$. I define $U$ and $S$ in $\lmap{V}$ as follows:
    \[
        \begin{split}
            U: (a_{1}, a_{2}, \ldots) \mapsto (0, a_{1}, a_{2}, \ldots) \\
            S: (a_{1}, a_{2}, \ldots) \mapsto (a_{2}, a_{3}, \ldots)
        \end{split}
    \]

    Then $STU = I$. However, $T^{-1} = I\ne US$ because $(1, 0, \ldots)$ is in $\kernel{US}$.
\end{proof}
\newpage

% chapter3:sectionD:exercise14
\begin{exercise}
    Prove or give a counterexample: If $V$ is a finite-dimensional vector space
    and $R, S, T \in \mathcal{L}(V)$ are such that $RST$ is surjective, then $S$ is injective.
\end{exercise}

\begin{proof}
    $RST\in\lmap{V}$, $V$ is finite-dimensional, and $RST$ is surjective, then it follows that $RST$ is invertible. According to Exercise~\ref{chapter3:sectionD:exercise12}, $S$ is invertible. So $S$ is injective.
\end{proof}
\newpage

% chapter3:sectionD:exercise15
\begin{exercise}
    Suppose $T \in \mathcal{L}(V)$ and $v_{1} , \ldots, v_{m}$ is a list in $V$ such that $Tv_{1}, \ldots, Tv_{m}$ spans $V$. Prove that $v_{1}, \ldots, v_{m}$ spans $V$.
\end{exercise}

\begin{proof}
    Since $Tv_{1}, \ldots, Tv_{m}$ spans $V$, it follows that $V$ is finite-dimensional, and $T$ is surjective. So $T$ is also invertible.

    Let $v$ be a vector in $V$, then there exist scalar $a_{k}$ for $k = 1, \ldots, m$ such that
    \[
        Tv = a_{1}Tv_{1} + \cdots + a_{m}Tv_{m}.
    \]

    So
    \begin{align*}
        v = T^{-1}(Tv) & = T^{-1}(a_{1}Tv_{1} + \cdots + a_{m}Tv_{m})         \\
                       & = a_{1}T^{-1}(Tv_{1}) + \cdots + a_{m}T^{-1}(Tv_{m}) \\
                       & = a_{1}v_{1} + \cdots + a_{m}v_{m}.
    \end{align*}

    Therefore $v_{1}, \ldots, v_{m}$ spans $V$.
\end{proof}
\newpage

% chapter3:sectionD:exercise16
\begin{exercise}
    Prove that every linear map from $\mathbb{F}^{n, 1}$ to $\mathbb{F}^{m, 1}$ is given by a matrix multiplication. In other words, prove that if $T \in \lmap{\mathbb{F}^{n, 1}, \mathbb{F}^{m, 1}}$, then there exists an $m$-by-$n$ matrix $A$ such that $Tx = Ax$ for every $x \in \mathbb{F}^{n, 1}$.
\end{exercise}

\begin{proof}
    Let $e_{1}, \ldots, e_{n}$ be the standard basis of $\mathbb{F}^{n,1}$, $f_{1}, \ldots, f_{m}$ the standard basis of $\mathbb{F}^{m,1}$.

    I define the matrix $A$ as follows:
    \[
        Te_{i} = \sum^{m}_{r=1}A_{r,i}f_{r}.
    \]

    Let $x = x_{1}e_{1} + \cdots + x_{n}e_{n}$ be a vector in $\mathbb{F}^{n,1}$.
    \begin{align*}
        Tx & = \sum^{n}_{i=1}T(x_{i}e_{i}) = \sum^{n}_{i=1}x_{i}Te_{i}     \\
           & = \sum^{n}_{i=1}x_{i}\left(\sum^{m}_{r=1}A_{r,i}f_{r}\right)  \\
           & = \sum^{m}_{r=1}\left(\sum^{n}_{i=1}A_{r,i}x_{i}\right)f_{r}.
    \end{align*}

    $\sum^{n}_{i=1}A_{r,i}x_{i}$ is the multiplication of $A_{r,\cdot}$ and $x$. So $Tx = Ax$.

    \bigskip

    Another solution: $\mathcal{M}(Tx) = \mathcal{M}(T)\mathcal{M}(x)$. Let $A = \mathcal{M}(T)$, then $Tx = Ax$ (in $\mathbb{F}^{n,1}$, $x = \mathcal{M}(x)$).
\end{proof}
\newpage

% chapter3:sectionD:exercise17
\begin{exercise}
    Suppose $V$ is finite-dimensional and $S\in\mathcal{L}(V)$. Define $\mathcal{A}\in \mathcal{L}(\mathcal{L}(V))$ by
    \[
        \mathcal{A}(T) = ST
    \]

    for $T\in\mathcal{L}(V)$.

    \begin{enumerate}[label={(\alph*)}]
        \item Show that $\dim\kernel{\mathcal{A}} = (\dim V)(\dim\kernel{S})$.
        \item Show that $\dim\range{\mathcal{A}} = (\dim V)(\dim\range{S})$.
    \end{enumerate}
\end{exercise}

\begin{proof}
    $\kernel{\mathcal{A}}$ consists of linear operators $T$ in $V$ such that $ST = 0$.

    $ST = 0$ if and only if $\range{T} \subseteq \kernel{S}$. I define the map $f$ from $\kernel{\mathcal{A}}$ to $\lmap{V, \kernel{S}}$ as follows: $T\mapsto \bar{T}$, where $Tv = \bar{T}v$. This map $f$ is linear and an isomorphism. Therefore $\kernel{\mathcal{A}}$ and $\lmap{V, \kernel{S}}$ are isomorphic, and
    \[
        \dim\kernel{\mathcal{A}} = \dim \lmap{V, \kernel{S}} = (\dim V)(\dim\kernel{S}).
    \]

    According to the fundamental theorem of linear maps
    \begin{align*}
        \dim\range{\mathcal{A}} & = \dim\lmap{V} - \dim\kernel{\mathcal{A}}      \\
                                & = (\dim V)(\dim V) - (\dim V)(\dim \kernel{S}) \\
                                & = (\dim V)(\dim V - \dim\kernel{S})            \\
                                & = (\dim V)(\dim\range{S}).\qedhere
    \end{align*}
\end{proof}
\newpage

% chapter3:sectionD:exercise18
\begin{exercise}
    Show that $V$ and $\mathcal{L}(\mathbb{F}, V)$ are isomorphic vector spaces.
\end{exercise}

\begin{proof}
    Let $v$ be a vector in $V$. I define a map $T_{v}$ in $\lmap{\mathbb{F}, V}$ as follows: $T_{v}: 1\mapsto v$. The map $v\mapsto T_{v}$ is a linear map.

    Let $S$ be a linear map in $\lmap{\mathbb{F}, V}$, and $v_{S} = S(1)$. The map $S\mapsto v_{S}$ is a linear map.

    Moreover, the two linear maps $v\mapsto T_{v}$ and $S\mapsto v_{S}$ are the inverses of each other. Therefore $V$ and $\mathcal{L}(\mathbb{F}, V)$ are isomorphic vector spaces.
\end{proof}
\newpage

% chapter3:sectionD:exercise19
\begin{exercise}
    Suppose $V$ is finite-dimensional and $T \in \lmap{V}$. Prove that $T$ has the same matrix with respect to every basis of $V$ if and only if $T$ is a scalar multiple of the identity operator.
\end{exercise}

\begin{proof}
    $(\Rightarrow)$ $T$ is a scalar multiple of the identity operator.

    Let $v_{1}, \ldots, v_{n}$ be an arbitary basis of $V$.

    $Tv_{k} = \lambda v_{k}$ for $k = 1,\ldots, n$. So the matrix of $T$ with respect to the basis $v_{1}, \ldots, v_{n}$ is
    \[
        \begin{pmatrix}
            \lambda & \cdots & 0       \\
            \vdots  & \ddots & \vdots  \\
            0       & \cdots & \lambda
        \end{pmatrix} = \lambda I
    \]

    which is independent of the basis.

    $(\Leftarrow)$ $T$ has the same matrix with respect to every basis of $V$.

    Let $u_{1}, \ldots, u_{n}$ and $v_{1}, \ldots, v_{n}$ be bases of $V$.
    \[
        A = \mathcal{M}(T, (u_{1}, \ldots, u_{n})) \qquad A = \mathcal{M}(T, (v_{1}, \ldots, v_{n}))
    \]

    Let $C$ be $\mathcal{M}(I, (u_{1}, \ldots, u_{n}), (v_{1}, \ldots, v_{n}))$, then $A = C^{-1}AC$.

    For every $i,j$ in $1,\ldots, n$ that $i\ne j$, let $C^{i,j}$ be a matrix in $\mathbb{F}^{n,n}$ where every entry is $0$ except that the entries in the diagonal are $1$ and in row $i$, column $j$ is $1$. Let $D^{i,j}$ be a matrix in $\mathbb{F}^{n,n}$ where every entry is $0$ except that the entries in the diagonal are $1$ and in row $i$, column $j$ is $-1$. $C^{i,j}D^{i,j} = D^{i,j}C^{i,j} = I$.

    $AC^{i,j}$ is the same as $A$, except that the column $j$ of $AC^{i,j}$ is the sum of the columns $i$ and $j$ of $A$. $C^{i,j}A$ is the same as $A$, except that the row $i$ of $C^{i,j}A$ is the sum of the rows $i$ and $j$ of $A$.

    Since $AC^{i,j} = C^{i,j}A$ for every $i\ne j$ in $1,\ldots, n$, it follows that
    \begin{itemize}
        \item $A_{i,k} = 0$ for $k\ne i$,
        \item $A_{k,j} = 0$ for $k\ne j$,
        \item $A_{i,i} = A_{j,j}$.
    \end{itemize}

    Let $A_{1,1} = \lambda$, then
    \[
        A = \begin{pmatrix}
            \lambda & \cdots & 0       \\
            \vdots  & \ddots & \vdots  \\
            0       & \cdots & \lambda
        \end{pmatrix} = \lambda I.
    \]

    So $T$ is a scalar multiple of the identity operator.
\end{proof}
\newpage

% chapter3:sectionD:exercise20
\begin{exercise}
    Suppose $q\in\mathcal{P}(\mathbb{R})$. Prove that there exists a polynomial $p\in\mathcal{P}(\mathbb{R})$ such that
    \[
        q(x) = (x^{2} + x)p''(x) + 2xp'(x) + p(3)
    \]

    for all $x\in\mathbb{R}$.
\end{exercise}

\begin{proof}
    Let $m$ be the degree of $q$. I define the linear map $T$ in $\lmap{\mathcal{P}_{m}(\mathbb{R})}$ as follow: $(Tp)(x) = (x^{2} + x)p''(x) + 2xp'(x) + p(3)$.

    $(x^{2} + x)p''(x) + 2xp'(x) + p(3) = 0$ for all $x\in\mathbb{R}$ if and only if $p = 0$. Therefore $T$ is injective. On the other hand, $\lmap{\mathcal{P}_{m}(\mathbb{R})}$ is finite-dimensional, so $T$ is invertible. So there exists a polynomial $p$ in $\mathcal{P}_{m}(\mathbb{R})$ such that $q(x) = (x^{2} + x)p''(x) + 2xp'(x) + p(3)$.
\end{proof}
\newpage

% chapter3:sectionD:exercise21
\begin{exercise}
    Suppose $n$ is a positive integer and $A_{j, k} \in \mathbb{F}$ for all $j, k = 1, \ldots, n$. Prove that the following are equivalent (note that in both parts below, the number of equations equals the number of variables).
    \begin{enumerate}[label={(\alph*)}]
        \item The trivial solution $x_{1} = \cdots = x_{n} = 0$ is the only solution to the homogeneous system of equations
              \begin{align*}
                  \sum^{n}_{k=1} A_{1,k}x_{k} & = 0    \\
                                              & \vdots \\
                  \sum^{n}_{k=1} A_{n,k}x_{k} & = 0    \\
              \end{align*}
        \item For every $c_{1}, \ldots, c_{n}\in\mathbb{F}$, there exists a solution to the system of equations
              \begin{align*}
                  \sum^{n}_{k=1} A_{1,k}x_{k} & = c_{1} \\
                                              & \vdots  \\
                  \sum^{n}_{k=1} A_{n,k}x_{k} & = c_{n} \\
              \end{align*}
    \end{enumerate}
\end{exercise}

\begin{proof}
    I define the linear map $T\in\lmap{\mathbb{F}^{n,1}}$ as follows: $Tx = Ax$, where $Ax$ is the matrix multiplication of $A$ and the column matrix $x$.

    (a) is equivalent to $T$ is injective. (b) is equivalent to $T$ is surjective. On the other hand, $T$ is injective if and only if $T$ is surjective. Therefore (a) and (b) are equivalent.
\end{proof}
\newpage

% chapter3:sectionD:exercise22
\begin{exercise}
    Suppose $T\in\mathcal{L}(V)$ and $v_{1},\ldots, v_{n}$ is a basis of $V$. Prove that
    \[
    \text{$\mathcal{M}(T, (v_{1}, \ldots, v_{n}))$ is invertible}\Longleftrightarrow \text{$T$ is invertible.}
    \]
\end{exercise}

\begin{proof}
    Let $A = \mathcal{M}(T, (v_{1}, \ldots, v_{n}))$.

    If $A$ is invertible, then there exists a matrix $B$ such that $AB = BA = I$. I define the linear map $S$ where
    \[
        Sv_{k} = \sum^{n}_{r=1}B_{r,k}v_{r}
    \]

    for $k = 1, \ldots, n$. Then
    \begin{align*}
        (ST)(v_{k}) & = S\left(\sum^{n}_{r=1}A_{r,k}v_{r} \right) = \sum^{n}_{r=1}A_{r,k}Sv_{r} \\
                    & = \sum^{n}_{r=1}A_{r,k}\left(\sum^{n}_{p=1}B_{p,r}v_{p}\right)            \\
                    & = \sum^{n}_{p=1}\left(\sum^{n}_{r=1}B_{p,r}A_{r,k}\right)v_{p}            \\
                    & = \sum^{n}_{p=1}I_{p,k}v_{p} = v_{k},                                     \\
        (TS)(v_{k}) & = T\left(\sum^{n}_{r=1}B_{r,k}v_{r}\right) = \sum^{n}_{r=1}B_{r,k}Tv_{r}  \\
                    & = \sum^{n}_{r=1}B_{r,k}\left(\sum^{n}_{p=1}A_{p,r}v_{p}\right)            \\
                    & = \sum^{n}_{p=1}\left(\sum^{n}_{r=1}A_{p,r}B_{r,k}\right)v_{p}            \\
                    & = \sum^{n}_{p=1}I_{p,k}v_{p} = v_{k}.
    \end{align*}

    So $ST = TS = \text{id}_{V}$. Therefore $T$ is invertible.

    If $T$ is invertible, then there exists $S\in\lmap{V}$ such that $ST = TS = \text{id}_{V}$.
    \[
        \begin{split}
            I = \mathcal{M}(\text{id}_{V}, (v_{1}, \ldots, v_{n})) = \mathcal{M}(ST, (v_{1}, \ldots, v_{n})) = \mathcal{M}(S, (v_{1}, \ldots, v_{n}))\mathcal{M}(T, (v_{1}, \ldots, v_{n})), \\
            I = \mathcal{M}(\text{id}_{V}, (v_{1}, \ldots, v_{n})) = \mathcal{M}(TS, (v_{1}, \ldots, v_{n})) = \mathcal{M}(T, (v_{1}, \ldots, v_{n}))\mathcal{M}(S, (v_{1}, \ldots, v_{n})).
        \end{split}
    \]

    So $\mathcal{M}(T, (v_{1}, \ldots, v_{n}))$ is invertible.
\end{proof}
\newpage

% chapter3:sectionD:exercise23
\begin{exercise}
    Suppose that $u_{1}, \ldots, u_{n}$ and $v_{1} \ldots, v_{n}$ are bases of $V$. Let $T\in\lmap{V}$ be such that $Tv_{k} = u_{k}$ for each $k = 1,\ldots, n$. Prove that
    \[
        \mathcal{M}(T, (v_{1}, \ldots, v_{n})) = \mathcal{M}(I, (u_{1}, \ldots, u_{n}), (v_{1}, \ldots, v_{n})).
    \]
\end{exercise}

\begin{proof}
    Because $Tv_{k} = u_{k}$ for each $k = 1,\ldots, n$, it follows that $\mathcal{M}(T, (v_{1}, \ldots, v_{n}), (u_{1}, \ldots, u_{n})) = I$.
    \begin{align*}
        \mathcal{M}(T, (v_{1}, \ldots, v_{n})) & = \mathcal{M}(TI, (v_{1}, \ldots, v_{n}))                                                                                      \\
                                               & = \mathcal{M}(T, (v_{1}, \ldots, v_{n}), (u_{1}, \ldots, u_{n}))\mathcal{M}(I, (u_{1}, \ldots, u_{n}), (v_{1}, \ldots, v_{n})) \\
                                               & = I\mathcal{M}(I, (u_{1}, \ldots, u_{n}), (v_{1}, \ldots, v_{n}))                                                              \\
                                               & = \mathcal{M}(I, (u_{1}, \ldots, u_{n}), (v_{1}, \ldots, v_{n})).\qedhere
    \end{align*}
\end{proof}
\newpage

% chapter3:sectionD:exercise24
\begin{exercise}
    Suppose $A$ and $B$ are square matrices of the same size and $AB = I$. Prove that $BA = I$.
\end{exercise}

\begin{proof}
    Let $n$ be the number of rows of $A$. $T_{A}, T_{B}$ are linear maps in $\lmap{\mathbb{F}^{n,1}}$ where $T_{A}x = Ax$ and $T_{B}x = Bx$.

    $AB = I$ means $T_{A}T_{B} = \text{id}_{\mathbb{F}^{n,1}}$. According to Exercise~\ref{chapter3:sectionD:exercise11}, $T_{A}$ and $T_{B}$ are invertible.
    \[
        T^{-1}_{A} = T^{-1}_{A}\text{id}_{\mathbb{F}^{n,1}} = T^{-1}_{A}(T_{A}T_{B}) = (T^{-1}_{A}T_{A})T_{B} = T_{B}.
    \]

    Therefore $T_{B}T_{A} = T^{-1}_{A}T_{A} = \text{id}_{\mathbb{F}^{n,1}}$, and $BA = I$.
\end{proof}
\newpage

\section{Products and Quotients of Vector Spaces}

% chapter3:sectionE:exercise1
\begin{exercise}
    Suppose $T$ is a function from $V$ to $W$. The graph of $T$ is the subset of $V\times W$ defined by
    \[
        \text{graph of $T$} = \{ (v, Tv)\in V\times W: v\in V \}.
    \]

    Prove that $T$ is a linear map if and only if the graph of $T$ is a subspace of $V\times W$.
\end{exercise}

\begin{proof}
    If $T$ is a linear map, then
    \begin{itemize}
        \item $(0,0)$ is in the graph of $T$.
        \item if $(v_{1}, Tv_{1})$ and $(v_{2}, Tv_{2})$ are in the graph of $T$ then $(v_{1} + v_{2}, Tv_{1} + Tv_{2}) = (v_{1} + v_{2}, T(v_{1} + v_{2}))$ is in the graph of $T$.
        \item if $(v, Tv)$ is in the graph of $T$, then $\lambda (v, Tv) = (\lambda v, \lambda Tv) = (\lambda v, T(\lambda v))$ is in the graph of $T$.
    \end{itemize}

    so the graph of $T$ is a subspace of $V\times W$.

    If the graph of $T$ is a subspace of $V\times W$, then for every $v_{1}, v_{2}\in V$ and $\lambda\in\mathbb{F}$,
    \begin{align*}
        (v_{1}, Tv_{1}) + (v_{2}, Tv_{2}) & = (v_{1}+v_{2}, Tv_{1} + Tv_{2}),  \\
        \lambda (v_{1}, Tv_{1})           & = (\lambda v_{1}, \lambda Tv_{1}).
    \end{align*}

    Due to the definition of a function and the graph of a function, $(v_{1}+v_{2}, Tv_{1} + Tv_{2}) = (v_{1} + v_{2}, T(v_{1} + v_{2}))$ and $(\lambda v_{1}, \lambda Tv_{1}) = (\lambda v_{1}, T(\lambda v_{1}))$.

    Therefore $Tv_{1} + Tv_{2} = T(v_{1} + V_{2})$ and $T(\lambda v_{1}) = \lambda Tv_{1}$. Hence $T$ is a linear map from $V$ to $W$.
\end{proof}
\newpage

% chapter3:sectionE:exercise2
\begin{exercise}
    Suppose that $V_{1} , \ldots, V_{m}$ are vector spaces such that $V_{1} \times \cdots \times V_{m}$ is finite-dimensional. Prove that $V_{k}$ is finite-dimensional for each $k = 1, \ldots, m$.
\end{exercise}

\begin{proof}
    Assume that at least one vector space $V_{k}$ is infinite-dimensional, then there exists a sequence $\{ v_{n} \}$ of vectors in $V_{k}$ such that any finite list from this sequence (starting from the first) is linearly independent. The sequence of vectors $\{ (\ldots, 0, v_{n}, 0, \ldots) \}$ satisfies the same property. Therefore $V_{1}\times \cdots \times V_{m}$ is infinite-dimensional.

    Hence $V_{k}$ is finite-dimensional for each $k = 1,\ldots, m$.
\end{proof}
\newpage

% chapter3:sectionE:exercise3
\begin{exercise}
    Suppose $V_{1} , \ldots, V_{m}$ are vector spaces. Prove that $\lmap{V_{1} \times \cdots\times V_{m} , W}$ and $\lmap{V_{1} , W} \times \cdots \times \lmap{V_{m} , W}$ are isomorphic vector spaces.
\end{exercise}

\begin{proof}
    I skip this exercise.
\end{proof}
\newpage

% chapter3:sectionE:exercise4
\begin{exercise}
    Suppose $W_{1} , \ldots, W_{m}$ are vector spaces. Prove that $\lmap{V, W_{1} \times \cdots \times W_{m}}$ and $\lmap{V, W_{1}} \times \cdots \times \lmap{V, W_{m}}$ are isomorphic vector spaces.
\end{exercise}

\begin{proof}
    I skip this exercise.
\end{proof}
\newpage

% chapter3:sectionE:exercise5
\begin{exercise}
    For $m$ a positive integer, define $V^{m}$ by
    \[
        V^{m} = \underbrace{V\times \cdots \times V}_{\text{$m$ times}}.
    \]

    Prove that $V^{m}$ and $\lmap{\mathbb{F}^{m}, V}$ are isomorphic vector spaces.
\end{exercise}

\begin{proof}
    Let $e_{1}, \ldots, e_{m}$ be a basis of $\mathbb{F}^{m}$.

    Let $(v_{1}, \ldots, v_{m})$ be a vector in $V^{m}$. I define a linear map $T$ from $V^{m}$ to $\lmap{\mathbb{F}^{m}, V}$ as follows: $T((v_{1}, \ldots, v_{m}))$ is the linear map that maps $e_{k}$ to $v_{k}$ for $k = 1,\ldots, m$.

    I define a linear map $S$ from $\lmap{\mathbb{F}^{m}, V}$ to $V^{m}$ as follows: $SF$ is $(Fe_{1}, \ldots, Fe_{m})$, where $F\in\lmap{\mathbb{F}^{n}, V}$.

    $ST = \text{id}_{\lmap{\mathbb{F}^{m}, V}}$ and $TS = \text{id}_{V^{m}}$, so $T$ and $S$ are isomorphism. Thus $V^{m}$ and $\lmap{\mathbb{F}^{m}, V}$ are isomorphic.
\end{proof}
\newpage

% chapter3:sectionE:exercise6
\begin{exercise}
    Suppose that $v$, $x$ are vectors in $V$ and that $U$, $W$ are subspaces of $V$ such that $v + U = x + W$. Prove that $U = W$.
\end{exercise}

\begin{proof}
    Because $v + U = x + W$, there exist vectors $u_{0}\in U$, $w_{0}\in W$ such that $v + 0 = x + w_{0}$ and $v + u_{0} = x + 0$. So $w_{0} = v - x$ and $u_{0} = x - v$. Therefore $v - x$ is in $U$ and $W$.

    Let $u$ be a vector in $U$. Because $v + U = x + W$, there exists a vector $w$ in $W$ such that $v + u = x + w$. $u = (x - v) + w\in W$, so $U\subseteq W$.

    Let $w$ be a vector in $W$. Because $v + U = x + W$, there exists a vector $u$ in $U$ such that $v + u = x + w$. $w = u + (v - x)\in U$, so $W\subseteq U$.

    Thus $U = W$.
\end{proof}
\newpage

% chapter3:sectionE:exercise7
\begin{exercise}
    Let $U = \{(x, y, z) \in \mathbb{R}^{3}: 2x + 3y + 5z = 0\}$. Suppose $A \subseteq \mathbb{R}^{3}$. Prove that $A$ is a translate of $U$ if and only if there exists $c\in\mathbb{R}$ such that
    \[
        A = \{ (x, y, z)\in\mathbb{R}^{3}: 2x + 3y + 5z = c \}.
    \]
\end{exercise}

\begin{proof}
    If there exists $c\in\mathbb{R}$ such that $A = \{ (x, y, z)\in\mathbb{R}^{3}: 2x + 3y + 5z = c \}$, let $(x_{1}, y_{1}, z_{1})$ and $(x_{2}, y_{2}, z_{2})$ be elements of $A$, then
    \[
        2(x_{2} - x_{1}) + 3(y_{2} - y_{1}) + 5(z_{2} - z_{1}) = c - c = 0.
    \]

    So $(x_{2} - x_{1}, y_{2} - y_{1}, z_{2} - z_{1})\in U$. Therefore $A$ is a translate of $U$.

    \bigskip
    If $A$ is a translate of $U$, then there exists $(x_{1}, y_{1}, z_{1})$ such that $A = (x_{1}, y_{1}, z_{1}) + U$. Let $(x_{2}, y_{2}, z_{2})$ be an element of $A$, then $(x_{2} - x_{1}, y_{2} - y_{1}, z_{2} - z_{1})\in U$, which means
    \[
        2x_{2} + 3y_{2} + 5z_{2} = 2x_{1} + 3y_{1} + 5z_{1}.
    \]

    Let $c = 2x_{1} + 3y_{1} + 5z_{1}$, we conclude that $A = \{ (x, y, z)\in\mathbb{R}^{3}: 2x + 3y + 5z = c \}$.
\end{proof}
\newpage

% chapter3:sectionE:exercise8
\begin{exercise}
    \begin{enumerate}[label={(\alph*)}]
        \item Suppose $T \in \lmap{V, W}$ and $c \in W$. Prove that $\{x \in V : Tx = c\}$ is either the empty set or is a translate of $\kernel{T}$.
        \item Explain why the set of solutions to a system of linear equations such as 3.27 is either the empty set or is a translate of some subspace of $\mathbb{F}^{n}$.
    \end{enumerate}
\end{exercise}

\begin{proof}
    I skip this exercise.
\end{proof}
\newpage

% chapter3:sectionE:exercise9
\begin{exercise}
    Prove that a nonempty subset $A$ of $V$ is a translate of some subspace of $V$ if and only if $\lambda v + (1 - \lambda)w\in A$ for all $v, w\in A$ and all $\lambda \in\mathbb{F}$.
\end{exercise}

In this exercise $\text{char}(\mathbb{F})\ne 2$. Here is a counterexample: $\mathbb{F} = \mathbb{F}_{2}$; $V = \mathbb{F}^{2}_{2}$ and $A = \{ (0,0), (0,1), (1,1) \}$.

\begin{proof}
    $(\Rightarrow)$ $A$ is a translate of a subspace $U$ of $V$.

    There exists a vector $v_{0}\in V$ such that $A = v_{0} + U$. If $v, w\in A$, then there exist vectors $u_{1}, u_{2}\in U$ such that $v = v_{0} + u_{1}$ and $w = v_{0} + u_{2}$. For every $\lambda\in\mathbb{F}$,
    \[
        \lambda v + (1 - \lambda)w = \lambda (v_{0} + u_{1}) + (1 - \lambda)(v_{0} + u_{2}) = v_{0} + \underbrace{(\lambda u_{1} + (1 - \lambda)u_{2})}_{\in U} \in A.
    \]

    $(\Leftarrow)$ $\lambda v + (1 - \lambda)w\in A$ for all $v, w\in A$ and all $\lambda \in\mathbb{F}$.

    Let $v_{0}$ be an element of $A$, and $U = \{ (-v_{0}) + a : a\in A \}$.

    Due to this definition and $v_{0}\in A$, it follows that $0\in U$.

    If $u\in U$, then $u + v_{0}\in A$. For all $\lambda\in\mathbb{F}$, $\lambda (u + v_{0}) + (1 - \lambda)v_{0}\in A$, we have $\lambda u + v_{0}\in A$, which means $\lambda u\in U$. So $U$ is closed under scalar multiplication.

    If $u_{1}, u_{2}\in U$ then $u_{1} + v_{0}, u_{2} + v_{0}\in A$.
    \[
        \frac{1}{2}(u_{1} + v_{0}) + \left(1 - \frac{1}{2}\right)(u_{2} + v_{0})\in A.
    \]

    Then $\frac{1}{2}(u_{1} + u_{2}) + v_{0}\in A$. Therefore $\frac{1}{2}(u_{1} + u_{2})\in U$. Since $U$ is closed under scalar multiplication, $u_{1} + u_{2}\in U$. So $U$ is closed under addition.

    Hence $U$ is a subspace of $V$, and $A = v_{0} + U$ is a translate of $U$.
\end{proof}
\newpage

% chapter3:sectionE:exercise10
\begin{exercise}
    Suppose $A_{1} = v + U_{1}$ and $A_{2} = w + U_{2}$ for some $v, w \in V$ and some subspaces $U_{1}, U_{2}$ of $V$. Prove that the intersection $A_{1} \cap A_{2}$ is either a translate of some subspace of $V$ or is the empty set.
\end{exercise}

\begin{proof}
    Assume that $A_{1}\cap A_{2}$ is a nonempty set. Let $v_{0}$ be an element of $A_{1}\cap A_{2}$.

    Let $a$ be an element of $A_{1}\cap A_{2}$, then $a - v_{0}\in U_{1}$ and $a - v_{0}\in U_{2}$. Therefore $a - v_{0}\in U_{1}\cap U_{2}$. So $a\in v_{0} + (U_{1}\cap U_{2})$, and $A_{1}\cap A_{2}\subseteq v_{0} + (U_{1}\cap U_{2})$.

    Let $b$ be an element of $v_{0} + (U_{1}\cap U_{2})$, then there exists $u\in U_{1}\cap U_{2}$ such that $b = v_{0} + u$. Because $u\in U_{1}$ and $u\in U_{2}$, it follows that $b\in v_{0} + U_{1} = v + U_{1}$ and $b\in v_{0} + U_{2} = w + U_{2}$. So $b\in A_{1}\cap A_{2}$.

    Hence $A_{1}\cap A_{2} = v_{0} + (U_{1}\cap U_{2})$. Thus $A_{1}\cap A_{2}$ is either the empty set or a translate of a subspace of $V$.
\end{proof}
\newpage

% chapter3:sectionE:exercise11
\begin{exercise}
    Suppose $U = \{(x_{1} , x_{2} , \ldots ) \in \mathbb{F}^{\infty} : x_{k} \ne 0 \text{ for only finitely many $k$} \}$.
    \begin{enumerate}[label={(\alph*)}]
        \item Show that $U$ is a subspace of $\mathbb{F}^{\infty}$.
        \item Prove that $\mathbb{F}^{\infty}/U$ is infinite-dimensional.
    \end{enumerate}
\end{exercise}

\begin{proof}
    \begin{enumerate}[label={(\alph*)}]
        \item I skip this exercise.
        \item Let $(p_{n})$ be the sequence of prime numbers.

              Let $u_{k}$ be the vector in $\mathbb{F}^{\infty}$ where the $n$th slot is $p^{n}_{k}$ and the other slots are $0$. $u_{1} + U, u_{2} + U, \ldots$ are pairwise distinct, since $u_{i} - u_{j}$ has infinite nonzero slots.

              Assume that $u_{1} + U$, \ldots, $u_{k} + U$ is linearly dependent, then there exist scalars $a_{1}, \ldots, a_{k}$ which are not all $0$ such that
              \[
                  (a_{1}u_{1} + U) + \cdots + (a_{k}u_{k} + U) = 0 + U.
              \]

              If $a_{i}\ne 0$ then $(a_{1}u_{1} + U) + \cdots + (a_{k}u_{k} + U)$ has infinite slots which are nonzero. Therefore the assumption is false, so for every positive integer $k$, $u_{1} + U$, $u_{2} + U$, \ldots, $u_{k} + U$ is linearly independent. Hence $\mathbb{F}^{\infty}/U$ is infinite-dimensional.
    \end{enumerate}
\end{proof}
\newpage

% chapter3:sectionE:exercise12
\begin{exercise}
    Suppose $v_{1} , \ldots, v_{m} \in V$. Let
    \[
        A = \{ \lambda_{1}v_{1} + \cdots + \lambda_{m}v_{m}: \lambda_{1}, \ldots,\lambda_{m}\in\mathbb{F} \text{ and } \lambda_{1} + \cdots + \lambda_{m} = 1 \}.
    \]
    \begin{enumerate}[label={(\alph*)}]
        \item Prove that $A$ is a translate of some subspace of $V$.
        \item Prove that if $B$ is a translate of some subspace of $V$ and $\{ v_{1}, \ldots, v_{m} \} \subseteq B$, then $A\subseteq B$.
        \item Prove that $A$ is a translate of some subspace of $V$ of dimension less than $m$.
    \end{enumerate}
\end{exercise}

\begin{proof}
    \begin{enumerate}[label={(\alph*)}]
        \item Let $v_{0}$ be a vector in $A$, then there exist scalars $\lambda_{k}$ for $k = 1, \ldots, m$ such that $\lambda_{1} + \cdots + \lambda_{m} = 1$ and
              \[
                  v_{0} = \lambda_{1}v_{1} + \cdots + \lambda_{m}v_{m}.
              \]

              Let $U = \{ a - v_{0} : a\in A \}$. Because $v_{0}\in A$, it follows that $0\in U$.

              Let $u, w$ be elements of $U$, then there exist scalars $x_{k}$ and $y_{k}$ for $k = 1,\ldots, m$ such that $x_{1} + \cdots + x_{m} = 1$, $y_{1} + \cdots + y_{m} = 1$, and
              \[
                  u + v_{0} = x_{1}v_{1} + \cdots + x_{m}v_{m}\qquad w + v_{0} = y_{1}v_{1} + \cdots + y_{m}v_{m}.
              \]
              \begin{align*}
                  (u + w) + v_{0} & = (u + v_{0}) + (w + v_{0}) + (-1)v_{0}                                                                                        \\
                                  & = (x_{1}v_{1} + \cdots + x_{m}v_{m}) + (y_{1}v_{1} + \cdots + y_{m}v_{m}) + (-1)(\lambda_{1}v_{1} + \cdots + \lambda_{m}v_{m}) \\
                                  & = (x_{1} + y_{1} - \lambda_{1})v_{1} + \cdots + (x_{m} + y_{m} - \lambda_{m})v_{m}.
              \end{align*}

              Since $\sum^{m}_{k=1}(x_{k} + y_{k} - \lambda_{k}) = \sum^{m}_{k=1}x_{k} + \sum^{m}_{k=1}y_{k} - \sum^{m}_{k=1}\lambda_{k} = 1 + 1 - 1 = 1$, then $(u + w) + v_{0}$ is in $A$. So $u + w$ is in $U$.

              For every scalar $\lambda\in\mathbb{F}$
              \begin{align*}
                  \lambda u + v_{0} & = (\lambda x_{1}v_{1} + \cdots + \lambda x_{m}v_{m} - \lambda v_{0}) + v_{0}                                  \\
                                    & = (\lambda x_{1}v_{1} + \cdots + \lambda x_{m}v_{k}) + (1 - \lambda)v_{0}                                     \\
                                    & = (\lambda x_{1} + (1 - \lambda)\lambda_{1})v_{1} + \cdots + (\lambda x_{m} + (1 - \lambda)\lambda_{m})v_{m}.
              \end{align*}

              Since $\sum^{m}_{k=1}(\lambda x_{k} + (1 - \lambda)\lambda_{k}) = \sum^{m}_{k=1}\lambda x_{k} + \sum^{m}_{k=1}(1 - \lambda)\lambda_{k} = \lambda + (1 - \lambda) = 1$, then $\lambda u + v_{0}$ is in $A$. So $\lambda u$ is in $U$.

              Hence $U$ is a vector space, and $A = v_{0} + U$, which is a translate of $U$.
        \item Let $B = v + W$, where $W$ is a subspace of $V$.

              Since $v_{k}\in B$ for $k = 1, \ldots, m$, it follows that $v_{k} - v\in W$.

              Let $\lambda_{1}v_{1} + \cdots + \lambda_{m}v_{m}$ be an element of $A$ (where $\lambda_{1} + \cdots + \lambda_{m} = 1$).
              \begin{align*}
                  (\lambda_{1}v_{1} + \cdots + \lambda_{m}v_{m}) - v & = (\lambda_{1}v_{1} + \cdots + \lambda_{m}v_{m}) - (\lambda_{1}v + \cdots + \lambda_{m}v) \\
                                                                     & = \lambda_{1}(v_{1} - v) + \cdots + \lambda_{m}(v_{m} - v).
              \end{align*}

              Because $\lambda_{1}(v_{1} - v) + \cdots + \lambda_{m}(v_{m} - v)$ is a linear combination of $v_{1} - v$, \ldots, $v_{m} - v$, then $(\lambda_{1}v_{1} + \cdots + \lambda_{m}v_{m}) - v\in W$. Hence $\lambda_{1}v_{1} + \cdots + \lambda_{m}v_{m}\in B$, which implies $A\subseteq B$.
        \item (Continue with (a)) Let $u$ be a vector in $U$, then $u + v_{0}$ is in $A$. Then there exist scalars $a_{k}$ for $k = 1, \ldots, m$ such that $a_{1} + \cdots + a_{m} = 1$ and
              \[
                  u + v_{0} = a_{1}v_{1} + \cdots + a_{m}v_{m}
              \]

              So
              \[
                  u = (a_{1} - \lambda_{1})v_{1} + \cdots + (a_{m} - \lambda_{m})v_{m}
              \]

              where $\sum^{m}_{k=1}(a_{k} - \lambda_{k}) = 1 - 1 = 0$.

              Let $x_{1}, \ldots, x_{m}$ be scalars such that $x_{1} + \cdots + x_{m} = 0$, then
              \[
                  (x_{1}v_{1} + \cdots + x_{m}v_{m}) + v_{0} = (x_{1} + \lambda_{1})v_{1} + \cdots + (x_{m} + \lambda_{m})v_{m}
              \]

              where $\sum^{m}_{k=1}(x_{k} + \lambda_{k}) = 0 + 1 = 1$. Then $x_{1}v_{1} + \cdots + x_{m}v_{m} = 0$.

              Hence
              \[
                  U = \{ x_{1}v_{1} + \cdots + x_{m}v_{m} : x_{1}, \ldots, x_{m}\in \mathbb{F} \text{ and } x_{1} + \cdots + x_{m} = 0 \}.
              \]

              I define a subspace $U_{1}$ of $V$ as the span of $v_{1}, \ldots, v_{m-1}$, and define a map $T$ from $U$ to $U_{1}$ as follows:
              \[
                  T: x_{1}v_{1} + \cdots + x_{m}v_{m} \mapsto x_{1}v_{1} + \cdots + x_{m-1}v_{m-1}.
              \]

              I define a map $S$ from $U_{1}$ to $U$ as follows:
              \[
                  S: x_{1}v_{1} + \cdots + x_{m-1}v_{m-1} \mapsto x_{1}v_{1} + \cdots + x_{m-1}v_{m-1} + (1 - x_{1} - \cdots - x_{m-1})v_{m}.
              \]

              $T$ and $S$ are linear maps and $ST = \text{id}_{U}$, $TS = \text{id}_{U_{1}}$. Therefore $T$ is an isomorphism and $U$ is isomorphic to $U_{1}$. The dimension of $U_{1}$ is less than or equal to $(m - 1)$, so the dimension of $U$ is less than $m$.

              Hence $A$ is the translate of a subspace of $V$ of dimension less than $m$.
    \end{enumerate}
\end{proof}
\newpage

% chapter3:sectionE:exercise13
\begin{exercise}
    Suppose $U$ is a subspace of $V$ such that $V/U$ is finite-dimensional. Prove that $V$ is isomorphic to $U \times (V/U)$.
\end{exercise}

\begin{proof}
    Let $T$ be the linear map from $V$ to $V/U$, which is defined by $Tv = v + U$. $Tv = 0 + U$ if and only if $v + U = 0 + U$. $v + U = 0 + U$ if and only if $v\in U$. So $\kernel{T} = U$.

    Let $v_{1} + U, \ldots, v_{n} + U$ be a basis of $V/U$, and $v$ a vector in $V$. There exist scalars $a_{k}$ for $k = 1,\ldots, n$ such that
    \[
        Tv = v + U = (a_{1}v_{1} + U) + \cdots + (a_{n}v_{n} + U).
    \]

    Hence for all $v\in V$, we have $v - (a_{1}v_{1} + \cdots + a_{n}v_{n})\in U$, so $V = U + \text{span}(v_{1}, \ldots, v_{n})$.

    If $v$ is a vector in $U \cap \text{span}(v_{1}, \ldots, v_{n})$, then $Tv = 0 + U = x_{1}Tv_{1} + \cdots + x_{n}Tv_{n}$ for some scalars $x_{1}, \ldots, x_{n}$. We deduce that $x_{1} = \cdots = x_{n} = 0$ because $Tv_{1}, \ldots, Tv_{n}$ is a basis of $V/U$. This implies $v = 0$, so $U \cap \text{span}(v_{1}, \ldots, v_{n}) = \{0\}$.

    Hence $V = U \oplus \text{span}(v_{1}, \ldots, v_{n})$. I define the map $S$ from $V$ to $U\times (V/U)$ as follows: $Sv = (u, v + U)$, where $v = u + (v - u)$, $u\in U$ and $v - u\in \text{span}(v_{1}, \ldots, v_{n})$ (the only way to write $v$ as the sum of a vector in $U$ and a vector in $\text{span}(v_{1}, \ldots, v_{n})$).

    Next, I prove that $S$ is a linear map.

    Let $w_{1}, w_{2}$ be vectors in $V$. There exist a unique $u_{1}\in U$ such that $w_{1} - u_{1}\in \text{span}(v_{1}, \ldots, v_{n})$, an a unique $u_{2}\in U$ such that $w_{2} - u_{2}\in \text{span}(v_{1}, \ldots, v_{n})$.
    \begin{align*}
        S(w_{1} + w_{2}) & = (u_{1} + u_{2}, T(w_{1} + w_{2})) \\
                         & = (u_{1} + u_{2}, Tw_{1} + Tw_{2})  \\
                         & = (u_{1}, Tw_{1}) + (u_{2}, Tw_{2}) \\
                         & = Sw_{1} + Sw_{2},                  \\
        S(\lambda w_{1}) & = (\lambda u_{1}, T(\lambda w_{1})) \\
                         & = (\lambda u_{1}, \lambda Tw_{1})   \\
                         & = \lambda (u_{1}, Tw_{1})           \\
                         & = \lambda Sw_{1}.
    \end{align*}

    So $S$ is indeed a linear map. I define a map $R$ from $U\times (V/U)$ to $V$ as follows:
    \[
        R((u, v + U)) = u + a_{1}v_{1} + \cdots + a_{n}v_{n},
    \]

    where $v + U = (a_{1}v_{1} + U) + \cdots + (a_{n}v_{n} + U)$ ($a_{1}, \ldots, a_{n}$ are unique because $v_{1} + U, \ldots, v_{n} + U$ is a basis of $V/U$).
    \begin{align*}
        R((u_{1}, w_{1} + U) + (u_{2}, w_{2} + U)) & = R((u_{1} + u_{2}, (w_{1} + w_{2}) + U))                                                 \\
                                                   & = (u_{1} + u_{2}) + ((b_{1} + c_{1})v_{1} + \cdots + (b_{n} + c_{n})v_{n})                \\
                                                   & \phantom{=}\text{where ($w_{1} + U = (b_{1}v_{1} + U) + \cdots + (b_{n}v_{n} + U))$}      \\
                                                   & \phantom{=}\text{and ($w_{2} + U = (c_{1}v_{1} + U) + \cdots + (c_{n}v_{n} + U)$)}        \\
                                                   & = (u_{1} + b_{1}v_{1} + \cdots + b_{n}v_{n}) + (u_{2} + c_{1}v_{1} + \cdots + c_{n}v_{n}) \\
                                                   & = R((u_{1}, w_{1} + U)) + R((u_{2}, w_{2} + U)),                                          \\
        R(\lambda (u_{1}, w_{1} + U))              & = R((\lambda u_{1}, \lambda w_{1} + U))                                                   \\
                                                   & = \lambda u_{1} + \lambda (c_{1}v_{1} + \cdots + c_{n}v_{n})                              \\
                                                   & = \lambda (u_{1} + c_{1}v_{1} + \cdots + c_{n}v_{n})                                      \\
                                                   & = \lambda R((u_{1}, w_{1} + U)).
    \end{align*}

    So $R$ is also a linear map. On the other hand,
    \begin{align*}
        (RS)(v)          & = R((u, v + U))                                                                  \\
                         & = R((u, (u + a_{1}v_{1} + \cdots + a_{n}v_{n}) + U))                             \\
                         & = R((u, (a_{1}v_{1} + \cdots + a_{n}v_{n}) + U))                                 \\
                         & = u + a_{1}v_{1} + \cdots + a_{n}v_{n}                                           \\
                         & = v,                                                                             \\
        (SR)((u, w + U)) & = S(u + d_{1}v_{1} + \cdots + d_{n}v_{n})                                        \\
                         & \phantom{=}\text{(where $w + U = (d_{1}v_{1} + U) + \cdots + (d_{n}v_{n} + U)$)} \\
                         & = (u, (d_{1}v_{1} + \cdots + d_{n}v_{n}) + U)                                    \\
                         & = (u, w + U).
    \end{align*}

    So $S$ and $R$ are isomorphisms. Thus $V$ is isomorphic to $U\times (V/U)$.
\end{proof}
\newpage

% chapter3:sectionE:exercise14
\begin{exercise}
    Suppose $U$ and $W$ are subspaces of $V$ and $V = U \oplus W$. Suppose $w_{1} , \ldots, w_{m}$ is a basis of $W$. Prove that $w_{1} + U, \ldots, w_{m} + U$ is a basis of $V/U$.
\end{exercise}

\begin{proof}
    Let $v$ be a vector in $V$. There exists a unique pair of vectors $u, w$ where $u\in U, w\in W$ such that $v = u + w$. Since $w_{1}, \ldots, w_{m}$ is a basis of $W$, there exist scalars $a_{k}$ for $k = 1,\ldots, m$ such that $w = a_{1}w_{1} + \cdots + a_{m}w_{m}$. Then
    \[
        v + U = (u + w) + U = w + U = a_{1}(w_{1} + U) + \cdots + a_{m}(w_{m} + U)
    \]

    which means $w_{1} + U, \ldots, w_{m} + U$ spans $V/U$.

    Suppose that $a_{1}(w_{1} + U) + \cdots + a_{m}(w_{m} + U) = 0 + U$, then $a_{1}w_{1} + \cdots + a_{m}w_{m}\in U$. But $U\cap W = \{0\}$ because $V = U\oplus W$, it follows that $a_{1} = \cdots = a_{m} = 0$. Therefore $w_{1} + U, \ldots, w_{m} + U$ is linearly independent.

    Hence $w_{1} + U, \ldots, w_{m} + U$ is a basis of $V/U$.
\end{proof}
\newpage

% chapter3:sectionE:exercise15
\begin{exercise}
    Suppose $U$ is a subspace of $V$ and $v_{1} + U, \ldots, v_{m} + U$ is a basis of $V/U$ and $u_{1} , \ldots, u_{n}$ is a basis of $U$. Prove that $v_{1} , \ldots, v_{m} , u_{1} , \ldots, u_{n}$ is a basis of $V$.
\end{exercise}

\begin{proof}
    If $a_{1}v_{1} + \cdots + a_{m}v_{m} \in U$, then
    \[
        a_{1}(v_{1} + U) + \cdots + a_{m}(v_{m} + U) = (a_{1}v_{1} + \cdots + a_{m}v_{m}) + U = 0 + U.
    \]

    This implies $a_{1} = \cdots = a_{m} = 0$, because $v_{1} + U, \ldots, v_{m} + U$ is a basis of $V/U$. So $\text{span}(v_{1}, \ldots, v_{m})\cap U = \{0\}$. Particularly, $a_{1}v_{1} + \cdots + a_{m}v_{m} = 0\in U$ if and only if $a_{1} = \cdots = a_{m}$, which means $v_{1}, \ldots, v_{m}$ is linearly independent.

    Let $v$ be a vector in $V$. There exist scalars $b_{1}, \ldots, b_{m}$ such that
    \[
        v + U = b_{1}(v_{1} + U) + \cdots + b_{m}(v_{m} + U) = (b_{1}v_{1} + \cdots + b_{m}v_{m}) + U
    \]

    because $v_{1} + U, \ldots, v_{m} + U$ is a basis of $V/U$. So $v - (b_{1}v_{1} + \cdots + b_{m}v_{m})\in U$. Therefore $V = U + \text{span}(v_{1}, \ldots, v_{m})$. Together with $U\cap \text{span}(v_{1}, \ldots, v_{m}) = \{0\}$, it follows that $V = U \oplus \text{span}(v_{1}, \ldots, v_{m})$.

    $v_{1}, \ldots, v_{m}$ is a basis of $\text{span}(v_{1}, \ldots, v_{m})$, $u_{1}, \ldots, u_{n}$ is a basis of $U$, so $v_{1} , \ldots, v_{m} , u_{1} , \ldots, u_{n}$ is a basis of $V$.
\end{proof}
\newpage

% chapter3:sectionE:exercise16
\begin{exercise}
    Suppose $\varphi \in \lmap{V,\mathbb{F}}$ and $\varphi\ne 0$. Prove that $\dim V/(\kernel{\varphi}) = 1$.
\end{exercise}

\begin{proof}
    Because $V/(\kernel{\varphi})$ is isomorphic to $\range{\varphi}$ and $\dim\range{\varphi} = 1$, it follows that $\dim V/(\kernel{\varphi}) = 1$.
\end{proof}
\newpage

% chapter3:sectionE:exercise17
\begin{exercise}
    Suppose $U$ is a subspace of $V$ such that $\dim V/U = 1$. Prove that there exists $\varphi \in \lmap{V, \mathbb{F}}$ such that $\kernel{\varphi} = U$.
\end{exercise}

\begin{proof}
    Because $\dim V/U = 1$, there exists a vector $w\in V$ such that $w + U$ is a basis of $V/U$.

    Let $T$ be the map from $V$ to $V/U$ where $Tv = v + U$. Let $\varphi$ be the map from $V$ to $\mathbb{F}$, defined by $\varphi v = \lambda$, where $Tv = v + U = \lambda w + U$. $\varphi$ is well-defined, because $w + U$ is a basis of $V/U$. $T$ and $\varphi$ are both linear maps.

    $\varphi v = 0$ if and only if $v + U = 0 + U$, equivalently, $v\in U$. So $\kernel{\varphi} = U$.

    I constructed a linear map $\varphi\in\lmap{V, \mathbb{F}}$ where $\kernel{\varphi} = U$.
\end{proof}
\newpage

% chapter3:sectionE:exercise18
\begin{exercise}
    Suppose that $U$ is a subspace of $V$ such that $V/U$ is finite-dimensional.
    \begin{enumerate}[label={(\alph*)}]
        \item Show that if $W$ is a finite-dimensional subspace of $V$ and $V = U + W$, then $\dim W \geq \dim V/U$.
        \item Prove that there exists a finite-dimensional subspace $W$ of $V$ such that $\dim W = \dim V/U$ and $V = U\oplus W$.
    \end{enumerate}
\end{exercise}

\begin{proof}
    Let's define $T\in\lmap{V, V/U}$ by $Tv = v + U$, then $\kernel{T} = U$.

    \begin{enumerate}[label={(\alph*)}]
        \item I consider $T\vert_{W}: W\to V/U$. Let $v + U$ be a vector in $V/U$, then $Tv = v + U$. Since $V = U + W$, there exist vector $u$ in $U$ and $w$ in $W$ such that $v = u + w$.
              \[
                  Tw = T(v - u) = (v - u) + U = v + U.
              \]

              Therefore $T\vert_{W}$ is surjective. Hence $\dim W\geq \dim V/U$, due to the fundamental theorem of linear maps.
        \item Let $w_{1} + U, \ldots, w_{n} + U$ be a basis of $V/U$.
              \[
                  a_{1}(w_{1} + U) + \cdots + a_{n}(w_{n} + U) = 0 + U
              \]

              if and only if $a_{1} = \cdots = a_{n} = 0$ because $w_{1} + U, \ldots, w_{n} + U$ be a basis of $V/U$. On the other hand,
              \[
                  (a_{1}w_{1} + \cdots + a_{n}w_{n}) + U = a_{1}(w_{1} + U) + \cdots + a_{n}(w_{n} + U)
              \]

              so $a_{1}w_{1} + \cdots + a_{n}w_{n}\in U$ if and only if $a_{1} = \cdots = a_{n} = 0$. Therefore $\text{span}(w_{1}, \ldots, w_{n})\cap U = \{ 0 \}$  and $a_{1}w_{1} + \cdots + a_{n}w_{n} = 0\in U$ if and only if $a_{1} = \cdots = a_{n} = 0$, which means $w_{1}, \ldots, w_{n}$ is linearly independent.

              Let $W = \text{span}(w_{1}, \ldots, w_{n})$. Because $w_{1}, \ldots, w_{n}$ is linearly independent, it follows that $w_{1}, \ldots, w_{n}$ is a basis of $W$ and then $\dim W = n = \dim V/U$.

              Let $v$ be a vector in $V$. Because $w_{1} + U, \ldots, w_{n} + U$ be a basis of $V/U$, there exist scalars $x_{1}, \ldots, x_{n}$ such that
              \[
                  Tv = a_{1}(w_{1} + U) + \cdots + a_{n}(w_{n} + U).
              \]

              Equivalently,
              \[
                  v + U = (a_{1}w_{1} + \cdots + a_{n}w_{n}) + U.
              \]

              Therefore $v - (a_{1}w_{1} + \cdots + a_{n}w_{n})\in U$, which means $V = U + W$. Together with $U\cap W = \{0\}$, we conclude that $V = U\oplus W$.
    \end{enumerate}
\end{proof}
\newpage

% chapter3:sectionE:exercise19
\begin{exercise}
    Suppose $T\in\lmap{V, W}$ and $U$ is a subspace of $V$. Let $\pi$ denote the quotient map from $V$ onto $V/U$. Prove that there exists $S\in\lmap{V/U, W}$ such that $T = S\circ \pi$ if and only if $U\subseteq \kernel{T}$.
\end{exercise}

\begin{proof}
    $(\Rightarrow)$ There exists $S\in\lmap{V/U, W}$ such that $T = S\circ \pi$.

    Let $u$ be a vector in $U$, then $Tu = S(\pi(u)) = S(0 + U) = 0$. So $u\in \kernel{T}$ for every $u\in U$, which means $U\subseteq \kernel{T}$.

    $(\Leftarrow)$ $U\subseteq \kernel{T}$.

    $v_{1} + U = v_{2} + U$ if and only if $v_{1} - v_{2}\in U$. $v_{1} - v_{2}\in U$ implies $v_{1} - v_{2}\in \kernel{T}$. $v_{1} - v_{2}\in \kernel{T}$ if and only if $v_{1} + \kernel{T} = v_{2} + \kernel{T}$.

    So the map $f: V/U\to V/(\kernel{T})$ where $f(v_{1} + U) = v_{1} + \kernel{T}$ is well-defined. $f$ is also a linear map.

    Let $\widetilde{T}$ be a map from $V/(\kernel{T})$ to $W$ where $\widetilde{T}(v + \kernel{T}) = Tv$. This map is well-defined and linear. Let $S = \widetilde{T}\circ f$, then for every $v\in V$
    \[
        S(v + U) = \widetilde{T}(f(v + U)) = \widetilde{T}(v + \kernel{T}) = Tv.
    \]

    Hence I constructed a linear map $S\in\lmap{V/U, W}$ such that $T = S\circ \pi$.
\end{proof}
\newpage

\section{Duality}

